---
title: "publications_LENS_igraph"
output:
  html_document:
    code_folding: hide
    toc: TRUE
    toc_float: TRUE
    toc_depth: 4
    collapsed: FALSE
    YAML: rmdformats::robobook
editor_options: 
  chunk_output_type: console
---


```{r setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#library(ggpubr)
library(tidyverse)
library(here) #use: here("subfolder", "filename")
library(httr)
library(jsonlite)
library(ggplot2)
library(ggrepel)
library(expss)
library(igraph)
library(rworldmap)
library(patchwork) 
library(fuzzyjoin)
library(Polychrome)

```

## Summary
This code follows **publications_LENS_preprocessing.Rmd** which processes the list of the 1019 included articles stored in **20201215_EGM_Net_all-articles_clean.csv** and runs a query via LENS API custom function to retrieve their detailed bibliographic information. Retrieved data is processed to remove duplicated records, resulting in 974 records with unique titles. The data is stored as a hierarchical data object with multiple levels of nested data tables (**record_df**  in **LENS_dataframe.RData**). 

This code produces collaboration plots and statistics using igraph package.


## Load data 
"20201215_EGM_Net_all-articles_clean.csv" file has all original 1019 articles, however, cleaned data frame from LENS has only 930 articles stored in "record_df_data.authors.ids_cleaned.csv". Author, country and affiliation cleaned data frames were created from LENS API records during the preprocessing step.

```{r get full list of publications, eval = TRUE}
#load(file = here("data", "LENS_dataframe_cleaned.RData")) #loads semi-cleaned LENS output from a Rdata object - "record_df"

dat <- read.csv(here("data", "20201215_EGM_Net_all-articles_clean.csv"))
dim(dat) #1019   16
#names(dat)
#hist(dat$year)


# #initial checks
# length(unique(dat$Title)) #1019
# title <- unique(dat$Title)
# length(unique(dat$DOI)) #only 184 DOI values and missing the value is stored as "" (change to NA later?)
# table(dat$Item_Type) #mostly articles
# hist(dat$Pub_Year, breaks = 70)
# table(dat$Manual_Tags) #stored as vectors of characters, tags separated by "; "
# #table(dat$Item_Type)["journalArticle"] # 959 journal articles

load(file = here("data", "LENS_dataframe_cleaned.RData")) #load semi-cleaned LENS output from a Rdata object record_df (list of lists)
names(record_df)
length(record_df$data.lens_id) #930
# length(record_df$data.title)
# length(record_df$data.date_published)
# length(record_df$data.fields_of_study)

record_df_930_basic <- tibble(lens_id = record_df$data.lens_id, title = record_df$data.title, year = record_df$data.year_published,  journal = record_df$data.source$title, fields = record_df$data.fields_of_study) #simplify
names(record_df_930_basic)
```

## Use igraph to create collaboration networks for authors   

```{r load  data, eval = TRUE}
#load preprocessed LENS data frame with cleaned authors names and ids
record_df_data.authors.ids <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv")) #loads cleaned authors dataframe from csv

#dim(record_df_data.authors.ids) #3453 rows
#names(record_df_data.authors.ids) #author ID is stored as "value"

#check how many authors and ids
#record_df_data.authors.ids %>% summarise(count = n_distinct(Author)) #2149
#record_df_data.authors.ids %>% summarise(count = n_distinct(value)) #2149

#check how many authors with same name but different ids
record_df_data.authors.ids %>%
    group_by(Author) %>%
    summarise(count = n_distinct(value)) %>%
    filter(count > 1) #0 - no such cases, clean data

#Load cleaned data frame with authors affiliations
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
#str(record_df_data.authors.aff)
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")
```

```{r coathorship analysis1, eval = TRUE}
#prepare data frame for igraph
dt <- data.frame(pub.id = record_df_data.authors.ids$data.lens_id, Author = record_df_data.authors.ids$Author, value = record_df_data.authors.ids$value)
#str(dt)

dt %>%
  inner_join(dt, by = "pub.id") %>%
  filter(value.x < value.y) %>%
  count(Author.x, Author.y) %>%
  graph_from_data_frame(directed = FALSE) -> g1 #with author names as vertices

# dt %>%
#   inner_join(dt, by = "pub.id") %>%
#   filter(Author.x < Author.y) %>%
#   count(value.x, value.y) %>%
#   graph_from_data_frame(directed = FALSE) -> g1 #with ids as vertices

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")
summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)

#overall graph statistics
graph.density(g1) #0.002426185 = quite sparse
transitivity(g1, type = "global") # 0.6636143 = probability that the neighbors of a node are also connected (also called the clustering coefficient)

#visualize our co-authorship graph network tbnet2 using different layouts
g1_graph_lkk <- layout.kamada.kawai(g1) 
g1_graph_nicely <- layout_nicely(g1) #choose an appropriate graph layout algorithm for the graph automatically

plot(g1, layout = g1_graph_lkk, vertex.label = NA, vertex.size = 2, vertex.color = "blue")
```

## Plot author collaboration network coloured by author affiliation country

```{r plot collaboration network with country, eval = TRUE}

#visualize our co-authorship graph network tbnet2 using different layouts
g1_graph_lkk <- layout.kamada.kawai(g1) 
g1_graph_nicely <- layout_nicely(g1) #choose an appropriate graph layout algorithm for the graph automatically

plot(g1, layout = g1_graph_lkk, vertex.label = NA, vertex.size = 2, vertex.color = "blue")
plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA) 

# # PLOT - remove least connected authors (vertices) from KK layout
# Remove <- which(degree(g1) < 4)
# g1i <- delete.vertices(g1, Remove)
# g1_graph_lkki <- g1_graph_lkk[-Remove, ]
# plot(g1i, layout = g1_graph_lkki, vertex.label = NA, vertex.size = 2)

# summary(g1i)

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")

#color components
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(comp_308)]$color = "green" #set nodes of component1 to green
V(g1)[names(V(g1)) %in% names(comp_164)]$color = "blue" #set nodes of component2 to blue
V(g1)[names(V(g1)) %in% names(comp_98)]$color = "red" #set nodes of component3 to red
V(g1)[names(V(g1)) %in% names(comp_57)]$color = "yellow" #set nodes of component3 to red
plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA)

summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)


## set one country per author
#prepare affiliations data of all authors (note the Authir field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")
#get affiliations of unique authors
record_df_data.authors.aff %>% 
  filter(Author %in% V(g1)$name)  %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code)) -> authors_all_aff #only picking first country code
#dim(authors_all_aff) #1784 (was 2879 rows - some authors are present multiple times)
length(V(g1)$name) #2084, so 300 authors have no country code
g1_Authors <- as.data.frame(V(g1)$name)
names(g1_Authors) <- "Author"
authors_all_aff <- left_join(g1_Authors, authors_all_aff, by = "Author")
str(authors_all_aff)
length(unique(authors_all_aff$country_code))


g1country <- set_vertex_attr(g1, "country", index = V(g1), authors_all_aff$country_code) #use the built-in function to set_vertex_attr to country_code
#V(g1country)$country
unique(V(g1country)$country)


## Generate random colors for country codes using library(Polychrome) - NOTE: matching colors in the country barplots

# set color palette
mycolors <- createPalette(length(unique(authors_all_aff$country_code)),  c("#ff0000", "#00ff00", "#0000ff"))
#swatch(mycolors)
authors_all_aff$country_color <- as.factor(authors_all_aff$country_code) #add new column, matching country_code
levels(authors_all_aff$country_color) <- unname(mycolors) #assign colors from the palette
#View(authors_all_aff)

g1country <- set_vertex_attr(g1country, "color", index = V(g1), as.character(authors_all_aff$country_color)) #assign colors to vertices
#V(g1country)$color
#US = #9E4000
#GB = #DDE49E

par(mfrow=c(1,1), mar = c(0,0,0,0))

#Use colors in the plot:
g1country_graph_nicely <- layout_nicely(g1country) #choose an appropriate graph layout algorithm for the graph 
plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))

```

```{r plot top4 components network, eval = TRUE}

pdf(here("lens-results", "components_top4.pdf"), width = 8, heigh = 8, pointsize = 18)
par(mfrow=c(1,1), mar = c(0,0,0,0))

V(g1)$color = "white" #set all nodes to white
V(g1)[comp_308]$color = "red" #set comp_max nodes to red
V(g1)[comp_164]$color = "blue" #set comp_max nodes to blue
V(g1)[comp_98]$color = "green" #set comp_max nodes to green
V(g1)[comp_57]$color = "yellow" #set comp_max nodes to yellow

plot(g1, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1)$color, alpha.f = .8))

dev.off()

```

```{r plot top4 components and countries, eval = TRUE}

pdf(here("lens-results", "components_top4_countries.pdf"), width = 16, heigh = 8, pointsize = 16)
par(mfrow=c(1,2), mar = c(0,0,1,0))

plot(g1, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1)$color, alpha.f = .8))
text(0, 1.1, label = "A. Four largest network components ")

plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))
text(0, 1.1, label = "B. Author country affiliations")

dev.off()

```

## NETWORK COMPONENTS

Components are non-connected groups of authors (silos)
We want to get top 4 silos and compare them in terms of manually assigned terms from the original map.
Also compare author affiliations (country).

```{r extract top4 components, eval = TRUE}
#str(g1)
#comps1 <- components(g1)
#groups(comps1)

#alt way to see components:
comps2 <- decompose(g1, min.vertices=2)
sapply(comps2, gorder) #counts number of vertices of each component 
sapply(comps2, gsize) #counts number of edges of each group 
sapply(comps2, diameter) #calculates diameter of each group 


# #a series of plots by component
# sapply(decompose(g1), plot)
# sapply(decompose(g1)[2], plot) #only second one
# sapply(decompose(g1)[2], vertex_attr) 

c <- components(g1)
sort_desc(c$csize)
table(c$csize<6) #70% of components have 5 or less authors
sort_desc(c$csize)[1:4] #sizes of the top 3 components
#comp_max <- which(c$membership == which.max(c$csize)) # get the largest component group
comp_308 <- which(c$membership == which(c$csize == 308)) # get the largest component group
comp_164 <- which(c$membership == which(c$csize == 164)) # get the largest component group
comp_98 <- which(c$membership == which(c$csize == 98)) # get the largest component group
comp_57 <- which(c$membership == which(c$csize == 57)) # get the largest component group
```


```{r plot top4 components, eval = TRUE}

pdf(here("lens-results", "components_top4.pdf"), width = 8, heigh = 8, pointsize = 18)
par(mfrow=c(1,1), mar = c(0,0,0,0))

V(g1)$color = "white" #set all nodes to white
V(g1)[comp_308]$color = "red" #set comp_max nodes to red
V(g1)[comp_164]$color = "blue" #set comp_max nodes to blue
V(g1)[comp_98]$color = "green" #set comp_max nodes to green
V(g1)[comp_57]$color = "yellow" #set comp_max nodes to green
plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA) 

dev.off()

```

```{r analyse top4 components, eval = TRUE}
## Which papers are represented by biggest components? - then try to connect to data on functional roles
#see publicationsfrom top 3 components
dt %>% filter(Author %in% names(comp_308)) %>% distinct(pub.id) -> authors_comp_308_pubids
dt %>% filter(Author %in% names(comp_164)) %>% distinct(pub.id) -> authors_comp_164_pubids
dt %>% filter(Author %in% names(comp_98)) %>% distinct(pub.id) -> authors_comp_98_pubids
dt %>% filter(Author %in% names(comp_57)) %>% distinct(pub.id) -> authors_comp_57_pubids

#get publication details 
record_df_930_basic %>% filter(lens_id %in% authors_comp_308_pubids$pub.id)  -> authors_comp_308_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_164_pubids$pub.id)  -> authors_comp_164_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_98_pubids$pub.id)  -> authors_comp_98_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_57_pubids$pub.id)  -> authors_comp_57_pubids_basic

authors_comp_top4_pubids_basic <- bind_rows(authors_comp_308_pubids_basic, authors_comp_164_pubids_basic, authors_comp_98_pubids_basic, authors_comp_57_pubids_basic, .id = "Comp")
#str(authors_comp_top4_pubids_basic)

#histogram of publication years
ggplot(authors_comp_top4_pubids_basic, aes(year, fill = Comp)) + geom_histogram(binwidth = 5)
#with feqpolygons for better readability
ggplot(authors_comp_top4_pubids_basic, aes(year, colour = Comp)) + geom_freqpoly(binwidth = 5)

#top ten "fileds" labels for publication from this component (note these are not manual tags used in the original map)
table(unlist(authors_comp_308_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_164_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_98_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_57_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)

```


```{r compare top4 components terms, eval = TRUE}
## use file lens_bibcouple/data/13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv - column all_outcomes_group
myterms <- read.csv(here("lens_bibcouple/data", "13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv")) #Subset of original map data containing vegetated strips terms
dim(myterms)
#names(myterms)
myterms$title <- str_to_lower(myterms$Title) #change to lowercase to make it easier to merge by title (using fuzzyjoin package)
myterms$all_outcomes_group <- str_to_title(myterms$all_outcomes_group) #change to titlecase to make it match with other plots made

#Fuzzy join of clusters with myterms dataset using title column
authors_comp_308_pubids_basic$title <- tolower(authors_comp_308_pubids_basic$title)
data_comp_308 <- stringdist_inner_join(authors_comp_308_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")
data_comp_308_terms <- unlist(strsplit(data_comp_308$all_outcomes_group, ";"))
authors_comp_164_pubids_basic$title <- tolower(authors_comp_164_pubids_basic$title)
data_comp_164 <- stringdist_inner_join(authors_comp_164_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")
data_comp_164_terms <- unlist(strsplit(data_comp_164$all_outcomes_group, ";"))
authors_comp_98_pubids_basic$title <- tolower(authors_comp_98_pubids_basic$title)
data_comp_98 <- stringdist_inner_join(authors_comp_98_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")
data_comp_98_terms <- unlist(strsplit(data_comp_98$all_outcomes_group, ";"))
authors_comp_57_pubids_basic$title <- tolower(authors_comp_57_pubids_basic$title)
data_comp_57 <- stringdist_inner_join(authors_comp_57_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")
data_comp_57_terms <- unlist(strsplit(data_comp_57$all_outcomes_group, ";"))

## count terms within each component and create barplots

p_wordfreq1 <- as.data.frame(table(data_comp_308_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 7 terms!
  rename(Terms = data_comp_308_terms) %>% #rename column
	ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Social", "Human use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Social" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq2 <- as.data.frame(table(data_comp_164_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 7 terms!
  rename(Terms = data_comp_164_terms) %>% #rename column
	ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Social", "Human use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels=scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Social" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight=.8, face="bold")) +
  theme(legend.position="none")

p_wordfreq3 <- as.data.frame(table(data_comp_98_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 6 terms!
  rename(Terms = data_comp_98_terms) %>% #rename column
  rbind(setNames(data.frame("Pollution", 0), c("Terms", "Freq"))) %>% #add 7th term with value 0
  ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Social", "Human use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) + 
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Social" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq4 <- as.data.frame(table(data_comp_57_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms
  rename(Terms = data_comp_57_terms) %>% #rename column
  ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Social", "Human use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Social" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) + labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

#Assemble into a single multi-panel plot:
p_wordfreq1 / p_wordfreq2 / p_wordfreq3 / p_wordfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1, 1)) +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

#save the figure 
ggsave(here("lens-results", "components_top4_terms.pdf"), width = 16, height = 8, units = "cm", dpi = 300, scale = 2)

```


## Get author affiliations by component

```{r compare top4 components authors, eval = TRUE}

#record_df_data.authors.ids_cleaned <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv"))
#str(record_df_data.authors.ids_cleaned) #this dataframe has no affiliation info 

#get affiliations of authors from  the cleaned affiliations dataframe
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

## Which authors are represented by biggest components? - then try to connect to data on their affiliation country
#see author ids for top 3 components
dt %>% filter(Author %in% names(comp_308)) -> authors_comp_308
dt %>% filter(Author %in% names(comp_164)) -> authors_comp_164
dt %>% filter(Author %in% names(comp_98)) -> authors_comp_98
dt %>% filter(Author %in% names(comp_57)) -> authors_comp_57


## component comp_308 (nr1)

length(unique(authors_comp_308$pub.id)) #148
length(unique(authors_comp_308$Author)) #308
length(unique(authors_comp_308$value)) #308

#get publications for the component with 308 authors (component 1):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_308$pub.id)) -> authors_comp_308_pubs #publications of the authors from the component 1
#str(authors_comp_308_pubs)

# publication details for the component with 308 authors (component 1):
authors_comp_308_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_308_pubs_details

#get affiliations for authors for the component with 308 authors (component 1):
dt %>%
  filter(Author %in% unique(authors_comp_308$Author)) %>% 
  distinct(pub.id) -> authors_308_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_308_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_308$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_308_aff #sort to have most recent on top and save

#str(authors_comp_308_aff) #622 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_308_aff$Author)) #300 unique authors captured
table(authors_comp_308_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_308_oneaff

#make a barplot of country codes for the component with 308 authors (component 1):
p_countryfreq1 <- as.data.frame(table(authors_comp_308_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.9) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_164 (component 2)

length(unique(authors_comp_164$pub.id)) #95
length(unique(authors_comp_164$Author)) #164
length(unique(authors_comp_164$value)) #164

#get publications for the component with 164 authors (component 2):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_164$pub.id)) -> authors_comp_164_pubs #publications of the authors from the component 2
#str(authors_comp_164_pubs)

# publication details for the component with 164 authors (component 2):
authors_comp_164_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_164_pubs_details

#get affiliations for authors for the component with 164 authors (component 2):
dt %>%
  filter(Author %in% unique(authors_comp_164$Author)) %>% 
  distinct(pub.id) -> authors_164_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_164_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_164$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_164_aff #sort to have most recent on top and save

#str(authors_comp_164_aff) #294 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_164_aff$Author)) #137 unique authors captured
table(authors_comp_164_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_164_oneaff

#make a barplot of country codes for the component with 164 authors (component 2):
p_countryfreq2 <- as.data.frame(table(authors_comp_164_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.6) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_98 (component 3)

#get publications for the component with 98 authors (component 3):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_98$pub.id)) -> authors_comp_98_pubs #publications of the authors from the component 3
#str(authors_comp_98_pubs)

# publication details for the component with 98 authors (component 3):
authors_comp_98_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_98_pubs_details

#get affiliations for authors for the component with 98 authors (component 3):
dt %>%
  filter(Author %in% unique(authors_comp_98$Author)) %>% 
  distinct(pub.id) -> authors_98_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_98_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_98$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_98_aff #sort to have most recent on top and save

#str(authors_comp_98_aff) #169 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_98_aff$Author)) #81 unique authors captured
table(authors_comp_98_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_98_oneaff

#make a barplot of country codes for the component with 98 authors (component 3):
p_countryfreq3 <- as.data.frame(table(authors_comp_98_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.4) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_57 (component 4)

#get publications for the component with 57 authors (component 4):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_57$pub.id)) -> authors_comp_57_pubs #publications of the authors from the component 4
#str(authors_comp_57_pubs)

# publication details for the component with 57 authors (component 4):
authors_comp_57_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_57_pubs_details

#get affiliations for authors for the component with 57 authors (component 4):
dt %>%
  filter(Author %in% unique(authors_comp_57$Author)) %>% 
  distinct(pub.id) -> authors_57_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_57_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_57$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_57_aff #sort to have most recent on top and save

#str(authors_comp_57_aff) #70 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_57_aff$Author)) #42 unique authors captured
table(authors_comp_57_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_57_oneaff

#make a barplot of country codes for the component with 57 authors (component 3):
p_countryfreq4 <- as.data.frame(table(authors_comp_57_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.06) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")



## Assemble individual barplots into a single multi-panel plot:
p_countryfreq1 / p_countryfreq2 / p_countryfreq3 / p_countryfreq4+
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1)) +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

g <- ggplot_build(p_countryfreq1)
unique(g$data[[1]]["fill"])


#save the figure 
ggsave(here("lens-results", "components_countries.pdf"), width = 16, height = 8, units = "cm", dpi = 300, scale = 2)

```

Set up a custom and consistent colour scheme for the country plots.

```{r recolor top4 components authors plot, eval = TRUE}
##get currently used color values, example:
#g <- ggplot_build(p_countryfreq1)
#unique(g$data[[1]]["fill"])

## Usecolors for country codes using library(Polychrome) - NOTE: matching colors in the country barplots

#extract colors for all countries used earlier in authors_all_aff network plot
authors_all_aff %>% group_by(country_code) %>% summarize(country_color = first(country_color)) -> country_colors_df
#View(country_colors_df)

## countries and new colours for all 4 top4 components:
#countries_top4 <- rbind(as.data.frame(table(authors_comp_308_oneaff$country_code)),
#as.data.frame(table(authors_comp_164_oneaff$country_code)),
#as.data.frame(table(authors_comp_98_oneaff$country_code)),
#as.data.frame(table(authors_comp_57_oneaff$country_code)) )
#unique(countries_top4$Var1) 

#across all - AU CA CH CZ DE FI FR GB GR HU NL NO NZ PH SE SK US CO ES ID JO JP RU TR IT PT
 # ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Codes, levels = c("US", "GB", "IT", "FR", "AU", "CA", "CH", "CZ", "DE", "FI", "GR", "HU", "NL", "NO", "NZ", "PH", "SE", "SK", "CO", "ES", "ID", "JO", "JP", "RU", "TR", "PT")))) + 
#    scale_fill_manual(values = c( "AU" = "#0D00FB", "CA" = "#006216", "CH" = "#F78A0D", "CO" = "#16FED5", "CZ" = "#FABFD2", "DE" = "#005569", "ES" = "#FD89D6", "FI" = "#9F8A35", "FR" = "#B3E0DE", "GB" = "#E3C1F9", "GR" = "#76535F", "HU" = "#E24522", "ID" = "#FE919B", "IT" = "#911660", "JO" = "#7516BE", "JP" = "#164794", "NL" = "#F50066", "NO" = "#169682", "NZ" = "#83AAD2", "PH" = "#86BCB6", "PT" = "#7D8665", "RU" = "#26B673", "SE" = "#77981C", "SK" = "#167EF6", "TR" = "#B4FFD7", "US" = "#2EADFB")) +


## use above colours consistently across all 4 panels/components:

## component comp_308 (nr1) - AU CA CH CZ DE FI FR GB GR HU NL NO NZ PH SE SK US
#make a barplot of country codes for the component with 308 authors (component 1):
p_countryfreq1 <- as.data.frame(table(authors_comp_308_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Codes, levels = c("AU", "CA", "CH", "CZ", "DE", "FI", "FR", "GB", "GR", "HU", "NL", "NO", "NZ", "PH", "SE", "SK", "US")))) + 
  geom_bar(stat = 'identity', width = 0.9) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c( "AU" = "#0D00FB", "CA" = "#006216", "CH" = "#F78A0D", "CZ" = "#CF2EFF", "DE" = "#005569", "FI" = "#9F8A35", "FR" = "#B3E0DE", "GB" = "#E3C1F9", "GR" = "#76535F", "HU" = "#E24522", "NL" = "#F50066", "NO" = "#169682", "NZ" = "#83AAD2", "PH" = "#86BCB6", "SE" = "#77981C", "SK" = "#167EF6", "US" = "#2EADFB")) +  
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_164 (component 2) - CA CO DE ES GR ID JO JP RU TR US
#make a barplot of country codes for the component with 164 authors (component 2):
p_countryfreq2 <- as.data.frame(table(authors_comp_164_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Codes, levels = c("CA", "CO", "DE", "ES", "GR", "ID", "JO", "JP", "RU", "TR", "US")))) + 
  geom_bar(stat = 'identity', width = 0.6) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c( "CA" = "#006216", "CO" = "#16FED5", "DE" = "#005569", "ES" = "#FD89D6","GR" = "#76535F", "ID" = "#FE919B", "JO" = "#7516BE", "JP" = "#164794", "RU" = "#26B673", "TR" = "#B4FFD7", "US" = "#2EADFB")) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_98 (component 3) - ES FI GB IT NL PT US
#make a barplot of country codes for the component with 98 authors (component 3):
p_countryfreq3 <- as.data.frame(table(authors_comp_98_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Codes, levels = c("ES", "FI", "GB", "IT", "NL", "PT", "US")))) + 
  geom_bar(stat = 'identity', width = 0.4) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c( "ES" = "#FD89D6", "FI" = "#9F8A35", "GB" = "#E3C1F9", "IT" = "#911660", "NL" = "#F50066", "NO" = "#169682", "PT" = "#7D8665","US" = "#4E79A7")) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## component comp_57 (component 4) - US
#make a barplot of country codes for the component with 57 authors (component 3):
p_countryfreq4 <- as.data.frame(table(authors_comp_57_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Codes, levels = c("US")))) + 
  geom_bar(stat = 'identity', width = 0.06) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c( "US" = "#2EADFB")) +
  labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none")


## Assemble individual barplots into a single multi-panel plot:
p_countryfreq1 / p_countryfreq2 / p_countryfreq3 / p_countryfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1)) +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

#save the figure 
ggsave(here("lens-results", "components_countries.pdf"), width = 16, height = 8, units = "cm", dpi = 300, scale = 2)
    
```


## AUTHOR CENTRALITY

```{r coathorship centrality measures, eval = TRUE}
#Calculating more centrality measures (degree, betweeness, closeness, eigenvector centrality, coreness)
metrics <- data.frame(
  deg = degree(g1),
  bet = betweenness(g1),
  clo = closeness(g1),
  eig = evcent(g1)$vector,
  cor = graph.coreness(g1)
  )

cor(metrics) #check for linear correlations
```


```{r most central authors, eval = TRUE}

#compute centrality measures for vertexes - degree (number of links to a given author)
g1_degree <- degree(g1) 
#hist(g1_degree) #a small number of high-degree vertexes - highly skewed

#plot with node colors reflecting their degree
cols_g1 <- setNames(colorRampPalette(c("white", "red"))(length(unique(g1_degree))), unique(g1_degree)) 
plot(g1, layout = g1_graph_lkk, vertex.label = NA, vertex.size = 2, vertex.color = cols_g1[degree(g1)])
#set the colours using vertex.color = cols[degree(g1_degree)]

#find authors with degree > X
authors_central <- g1_degree[g1_degree > 5] #10 people for >25, 59 for > 15, 163 for >10, 639 for >5
length(names(authors_central))


#plot central authors as red, rest as white
#comp_164 <- which(g1$membership == which(c$csize == 164)) # get the id numbers
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(authors_central)]$color = "red" #set nodes to red
plot(g1, layout = g1_graph_lkk, vertex.size = 2, vertex.label = NA)

#get publications by central authors
dt %>% 
  filter(Author %in% names(authors_central)) %>% 
  distinct(pub.id) -> authors_central_pubids

#str(authors_central_pubids)
#record_df_data.authors.ids$data.lens_id

#get details of publications of central authors
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% authors_central_pubids$pub.id) -> authors_central_pubs
#str(authors_central_pubs)
#length(unique(authors_central_pubs$Author)) #these are all authors, many are not-central

#central authors with their papers details:
authors_central_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_central_pubs_details

#authors_central_pubs_details$data.lens_id #central authors with their papers ids
length(unique(authors_central_pubs_details$data.lens_id)) # publications across all central authors

#prepare affiliations data of all authors (note the Authir field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

#get affiliations of central authors
record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_central_pubs_details$data.lens_id) %>%
  filter(Author %in% names(authors_central)) -> authors_central_aff

#str(authors_central_aff) #191 rows 
unique(authors_central_aff$Author) # unique authors captured

# #count number of papers (data.title) per Author
# authors_central_aff %>% 
#   group_by(Author) %>%
#   count()
#   
# #collapse country codes
# # authors_central_aff %>% 
# #   group_by(Author) %>%
# #   summarize(country_code = paste(country_code, collapse = "; ")) 
# #only use first country code:
# authors_central_aff %>% 
#   group_by(Author) %>%
#   arrange((data.year_published)) %>%
#   summarize(country_code = first(country_code))  #only picking first one, mostly GB

#retain more columns
authors_central_aff %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code), affiliation = first(name), N_publications = n()) -> authors_central_table  #only picking first country code and adding counts of publications

authors_central_table$affiliation <- gsub(",.*", "", authors_central_table$affiliation) #truncate affiliations at first comma

#length(authors_central) #639
#dim(authors_central_table) #582
authors_central <- authors_central[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_central) == authors_central_table$Author #check if order of names is matching

#add and arrange in a data frame:
authors_central_table$Centrality <- unname(authors_central) #add a column with degrees centrality
authors_central_table$component_orig <- as.numeric(c$membership[names(authors_central)])

#check cluster numbers - for recoding to 1 2 3 4 - used below
# as.numeric(c$membership[unique(authors_central_aff$Author)]) #pick 2 5 20 51 - see below:
# which(c$csize == 308) #2
# which(c$csize == 164) #5
# which(c$csize == 98) #20
# which(c$csize == 57) #51
authors_central_table$component_nr <- case_when(authors_central_table$component_orig == 2 ~ 1,
                                         authors_central_table$component_orig == 5 ~ 2,
                                         authors_central_table$component_orig == 20 ~ 3,
                                         authors_central_table$component_orig == 51 ~ 4
                                         ) #we only assign numbers 1,2,3,4 to members of the three biggest clusters, rest is NA

#rearrange columns and sort by cluster and centrality
authors_central_table %>% 
  select(component_nr, Centrality, country_code, Author, affiliation, N_publications) %>% 
  arrange(component_nr, Centrality) %>% 
  arrange(desc(Centrality)) %>% 
  group_by(component_nr) %>%
  slice(1:10) %>%  #pick top 10 from each component
  filter(component_nr != "NA") ->  #remove "NA" component
  authors_central_table 
  #knitr::kable() %>%
  #View()

#AUTHOR BETWEENNES
g1_bet <- betweenness(g1)
hist(g1_bet) #highly skewed
authors_bet <- g1_bet[g1_bet > 1] #326 with betweenes score >1: length(names(authors_bet))
authors_bet <- authors_bet[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_bet) == authors_central_table$Author #check if order of names is matching
authors_central_table$Betweenness <- round(unname(authors_bet), 1) #add a column with degrees centrality

write.csv(authors_central_table, file = here("lens-results", "authors_central_table.csv"))

```



########################## OLD CODE DO NOT USE! #########################

## Clustering of authors (communities)

```{r explore coathorship communities, eval = FALSE}

#plot(g1) #basic plot - not readable
plot(g1, edge.arrow.size = 0, vertex.color="gold", vertex.size = 5, 
     vertex.frame.color = "gray", vertex.label.color = "black", 
     vertex.label.cex = 0.8, vertex.label.dist = 2, edge.curved=0.2, vertex.label=NA)


g1s <- simplify( g1, remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) #simplify by removing loops and merging overlapping edges
plot(g1s, edge.arrow.size = 0, vertex.color="gold", vertex.size = 5, vertex.frame.color = "gray", 
     vertex.label.color = "black", vertex.label.cex = 0.8, vertex.label.dist=2, edge.curved = 0.2, vertex.label = NA)
#similar plot

E(g1s)$weight <- 1 #add weights of 1 to each connection
E(g1s)$width <- E(g1s)$weight*2 #add weights to edges

#grep("^layout_", ls("package:igraph"), value=TRUE)[-1]  #list of available layouts 
plot(g1s, layout = layout_nicely, edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = 2,
     vertex.frame.color = "gray", vertex.label.color = "black", vertex.label = NA) # plotting with specific layout and without node labels

##Find cliques (complete subgraphs of an undirected graph)
# g1s_cliques <- cliques(as.undirected(g1s), min=10)# list of cliques       
# hist(sapply(g1s_cliques, length)) # histogram of clique sizes
# g1s_cliques_largest <- largest_cliques(as.undirected(g1s)) # cliques with max number of nodes
# vcol <- rep("grey80", vcount(as.undirected(g1s)))
# vcol[unlist(g1s_cliques_largest)] <- "gold"
# plot(as.undirected(g1s), layout=layout_nicely, vertex.color=vcol, vertex.size=2, vertex.label=NA)

##Community detection based on edge betweenness (Newman-Girvan)
##High-betweenness edges are removed sequentially (recalculating at each step) and the best partitioning of the network is selected.
ceb <- cluster_edge_betweenness(as.undirected(g1s)) 
length(ceb) #279 communities
#membership(ceb) #authors and community number
modularity(ceb) #high modularity 0.967
plot(ceb, as.undirected(g1s), layout=layout_nicely, vertex.size=2, vertex.label=NA)

#Community detection based on based on propagating labels
clp <- cluster_label_prop(g1s)
plot(clp, g1s, layout=layout_nicely, edge.arrow.size=0.0, vertex.size=2, vertex.label=NA)

#Community detection based on greedy optimization of modularity
cfg <- cluster_fast_greedy(as.undirected(g1s))
plot(cfg, as.undirected(g1s), layout=layout_nicely, edge.arrow.size=0.0, vertex.size=2, vertex.label=NA)
length(cfg) #280 communities
modularity(cfg) #high modularity
#order(sizes(cfg), decreasing=TRUE)
order(sizes(cfg), decreasing=TRUE)[1] # largest community nr1
members_1 <- membership(cfg)[membership(cfg)==1] #members of the community nr1
names(members_1)
members_2 <- membership(cfg)[membership(cfg)==2] #members of the community nr2
names(members_2)

#remove all nodes not from community1,  by name
g1s1 <- delete_vertices(g1s, names(membership(cfg)[membership(cfg)!=1]))
plot(g1s1, layout=layout_nicely, edge.arrow.size=0, vertex.color="gold", vertex.size=5, vertex.frame.color="gray", 
     vertex.label.color="black", vertex.label.cex=0.8, vertex.label.dist=2, edge.curved=0.2) #plot of largest community (nr1)

#gather information related to authors in community1:
members_1_data <- subset(record_df_data.authors.ids, record_df_data.authors.ids$Author %in% names(members_1))
dim(members_1_data) #more rows than authors, as it also has information on every associated publication (267)
length(unique(members_1_data$Author)) #97 authors
length(unique(members_1_data$data.title)) #59 titles

#Note: in order to get affliation data it needs to be merged with info from record_df_data.authors.aff (loaded in the next chunk, author details not cleaned)

#plot_dendrogram(ceb, mode="hclust") #dendogram plot - too dense!

#more at: https://kateto.net/netscix2016.html
```

## Use igraph to create collaboration networks for countries      

Countries codes are mostly cleaned now. We use two-letter country codes (fips) from https://www.geonames.org/countries/.

```{r collaboration networks countries}
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
#names(record_df_data.authors.aff)

record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep=", ") #this would need some extra cleaning to perfectly match Author field in record_df_data.authors.ids

#remove records with missing coutry code
table(is_na(record_df_data.authors.aff$country_code))
record_df_data.authors.aff %>% 
  drop_na(country_code) -> record_df_data.authors.aff
table(is_na(record_df_data.authors.aff$country_code))

#prepare data frame for igraph
dtc <- data.frame(pub.id = record_df_data.authors.aff$data.lens_id, Author = record_df_data.authors.aff$Author, value = record_df_data.authors.aff$country_code)
#str(dtc)

dtc %>%
  inner_join(dtc, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) -> g1c

summary(g1c) #IGRAPH 7cb8542 UN-- 49 213 -- + attr: name (v/c), n (e/n)

#as_data_frame(g1c, what = "edges")

# plot(g1c)
# plot(g1c, edge.arrow.size=0, vertex.color="gold", vertex.size=5, 
#      vertex.frame.color="gray", vertex.label.color="black", 
#      vertex.label.cex=0.8, vertex.label.dist=2, edge.curved=0.2)

#E(g1c)$weight <- 1 #add weights

g1cs <- simplify(g1c, remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) #simplify
plot(g1cs, layout = layout_nicely, edge.arrow.size = 0, vertex.color = "gold", vertex.size = 10, vertex.frame.color = "gray", 
     vertex.label.color = "black", vertex.label.cex = 0.8, vertex.label.dist = 0, edge.curved = 0.2)
#E(g1cs)
#V(g1cs)

##Find cliques (complete subgraphs of an undirected graph)
# cliques(as.undirected(g1cs)) # list of cliques       
# sapply(cliques(as.undirected(g1cs)), length) # clique sizes
# largest_cliques(as.undirected(g1cs)) # clique with max number of nodes
# vcol <- rep("grey80", vcount(as.undirected(g1cs)))
# vcol[unlist(largest_cliques(as.undirected(g1cs)))] <- "gold"
# plot(as.undirected(g1cs), vertex.label=V(g1cs)$name, vertex.color=vcol)

deg <- degree(g1cs, mode = "all") # Count the number of degree for each node
#record_df_data.authors.aff[record_df_data.authors.aff$country_code == "NA", ] #some odd records? - rmove before plotting network, otherwise "NA" appears as a country (Namibia) #View(record_df_data.authors.aff)

##Community detection based on edge betweenness (Newman-Girvan)
##High-betweenness edges are removed sequentially (recalculating at each step) and the best partitioning of the network is selected.
cebc <- cluster_edge_betweenness(as.undirected(g1cs)) 

#dendPlot(cebi, mode="hclust") #using deg fo sizing the vertices
plot(cebc, as.undirected(g1cs), layout = layout_nicely, edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg,
     vertex.frame.color = "grey", vertex.label.color = "black") #, vertex.label=NA, 

#more at: https://kateto.net/netscix2016.html, pretty_plots.R
```

Make series of graph by decade

```{r collaboration networks country decade}
#names(record_df_data.authors.aff)
hist(record_df_data.authors.aff$data.year_published)
hist(dtc$data.year_published)

## before 2000
record_df_data.authors.aff %>% 
  filter(data.year_published > 1950 & data.year_published <= 2000) -> record_df_data.authors.aff_2000
dtc_2000 <- data.frame(pub.id = record_df_data.authors.aff_2000$data.lens_id, Author = record_df_data.authors.aff_2000$Author, value = record_df_data.authors.aff_2000$country_code)
dtc_2000 %>%
  inner_join(dtc_2000, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2000 #simplify
deg_2000 <- degree(g1cs_2000, mode = "all") # Count the number of degree for each node
cebc_2000 <- cluster_edge_betweenness(as.undirected(g1cs_2000)) 
#dendPlot(cebi, mode="hclust") #using deg for sizing the vertices
p_2000 <- plot(cebc_2000, as.undirected(g1cs_2000), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2000,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, 
     main = "pre-2001")

## decade 2001 - 2010
record_df_data.authors.aff %>% 
  filter(data.year_published >= 2000 & data.year_published <= 2010) -> record_df_data.authors.aff_2010
dtc_2010 <- data.frame(pub.id = record_df_data.authors.aff_2010$data.lens_id, Author = record_df_data.authors.aff_2010$Author, value = record_df_data.authors.aff_2010$country_code)
dtc_2010 %>%
  inner_join(dtc_2010, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2010 #simplify
deg_2010 <- degree(g1cs_2010, mode = "all") # Count the number of degree for each node
cebc_2010 <- cluster_edge_betweenness(as.undirected(g1cs_2010)) 
#dendPlot(cebi, mode="hclust") #using deg fo sizing the vertices
p_2010 <- plot(cebc_2010, as.undirected(g1cs_2010), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2010,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA,
     main = "2001-2010") 

## decade 2011 - 2020
record_df_data.authors.aff %>% 
  filter(data.year_published >= 2010) -> record_df_data.authors.aff_2020
dtc_2020 <- data.frame(pub.id = record_df_data.authors.aff_2020$data.lens_id, Author = record_df_data.authors.aff_2020$Author, value = record_df_data.authors.aff_2020$country_code)
dtc_2020 %>%
  inner_join(dtc_2020, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2020 #simplify
deg_2020 <- degree(g1cs_2020, mode = "all") # Count the number of degree for each node
cebc_2020 <- cluster_edge_betweenness(as.undirected(g1cs_2020)) 
p_2020 <- plot(cebc_2020, as.undirected(g1cs_2020), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = NA, vertex.size = deg_2020,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA,
     main = "2011-2020")

```

Assemble into a multi-panel plot

```{r collaboration networks country decades multipanel}

pdf(here("lens-results", "country_collab_decades.pdf"), width = 18, heigh = 8, pointsize = 18)

par(mfrow=c(1,3), mar = c(0,0,1,0))
#par(mfrow=c(1,1), mar = c(0,0,0,0))

p_2000 <- plot(cebc_2000, as.undirected(g1cs_2000), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2000*2, edge.color = "grey",
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "pre-2001")

p_2010 <- plot(cebc_2010, as.undirected(g1cs_2010), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2010*2,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "2001 - 2010") 

p_2020 <- plot(cebc_2020, as.undirected(g1cs_2020), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "white", vertex.size = deg_2020*2,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "2011 - 2020")

dev.off()

```


Plot country collaboration on a map

```{r collaboration networks country map - all years}

#worldmap <- getMap() #use data from package rworldmap
worldmap <- getMap()[-which(getMap()$ADMIN=="Antarctica"),] #use data from package rworldmap and remove Antarctica 
#worldmap <- spTransform(worldmap, CRS=CRS("+proj=robin +ellps=WGS84")) #transform to robin for the Robinson projection - messess up coordinates for the lines and points, because the country centroid coordinate used for plotting does not get transformed - needs rgdal package - install.packages("rgdal")
worldmap_names <- select(as.data.frame(worldmap), ISO_A2) #extract country codes
worldmap_names <- levels(worldmap_names$ISO_A2) #make names into a character vector

dtc %>%
  inner_join(dtc, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc

names(dtcc) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_coord <- dtcc %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_coord_diff <- filter(dtcc_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_coord_same <- filter(dtcc_coord, country.x == country.y) # points with the same countries - use for points

fig_map_allyears <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_coord_diff$links)) +
  geom_point(
    data = dtcc_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations", caption = "circles = national collaborations (log10), lines = international coollaborations") 
```

##ALTERNATIVE: https://www.r-bloggers.com/2018/05/three-ways-of-visualizing-a-graph-on-a-map/

Plot by decade and assemble into a multi-panel plot map 

```{r collaboration networks country map - decades}

#worldmap <- getMap() #use data from package rworldmap
worldmap <- getMap()[-which(getMap()$ADMIN=="Antarctica"),] #use data from package rworldmap and remove Antarctica 
#worldmap <- spTransform(worldmap, CRS=CRS("+proj=robin +ellps=WGS84")) #transform to robin for the Robinson projection - messess up coordinates for the lines and points, because the country centroid coordinate used for plotting does not get transformed
worldmap_names <- select(as.data.frame(worldmap), ISO_A2) #extract country codes
worldmap_names <- levels(worldmap_names$ISO_A2) #make names into a character vector

## before 2000
record_df_data.authors.aff %>% 
  filter(data.year_published > 1950 & data.year_published <= 2000) -> record_df_data.authors.aff_2000

dtc_2000 <- data.frame(pub.id = record_df_data.authors.aff_2000$data.lens_id, Author = record_df_data.authors.aff_2000$Author, value = record_df_data.authors.aff_2000$country_code)

dtc_2000 %>%
  inner_join(dtc_2000, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2000

names(dtcc_2000) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2000_coord <- dtcc_2000 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2000_coord_diff <- filter(dtcc_2000_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2000_coord_same <- filter(dtcc_2000_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2000 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2000_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2000_coord_diff$links)) +
  geom_point(
    data = dtcc_2000_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2000_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations pre-2000", caption = "circles = national collaborations (log10), lines = international coollaborations") 

## decade 2000 - 2010
record_df_data.authors.aff %>% 
  filter(data.year_published > 2000 & data.year_published <= 2010) -> record_df_data.authors.aff_2010
dtc_2010 <- data.frame(pub.id = record_df_data.authors.aff_2010$data.lens_id, Author = record_df_data.authors.aff_2010$Author, value = record_df_data.authors.aff_2010$country_code)

dtc_2010 %>%
  inner_join(dtc_2010, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2010

names(dtcc_2010) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2010_coord <- dtcc_2010 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2010_coord_diff <- filter(dtcc_2010_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2010_coord_same <- filter(dtcc_2010_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2010 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2010_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2010_coord_diff$links)) +
  geom_point(
    data = dtcc_2010_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2010_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations 2000 - 2010", caption = "circles = national collaborations (log10), lines = international coollaborations") 


## decade 2010 - 2020
record_df_data.authors.aff %>% 
  filter(data.year_published > 2010 & data.year_published <= 2020) -> record_df_data.authors.aff_2020
dtc_2020
dtc_2020 <- data.frame(pub.id = record_df_data.authors.aff_2020$data.lens_id, Author = record_df_data.authors.aff_2020$Author, value = record_df_data.authors.aff_2020$country_code)

dtc_2020 %>%
  inner_join(dtc_2020, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2020

names(dtcc_2020) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2020_coord <- dtcc_2020 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2020_coord_diff <- filter(dtcc_2020_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2020_coord_same <- filter(dtcc_2020_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2020 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2020_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2020_coord_diff$links)) +
  geom_point(
    data = dtcc_2020_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2020_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations 2010 - 2020", caption = "circles = national collaborations (log10), lines = international coollaborations") 

```

Assemble into a single multi-panel plot

```{r collaboration map country decades multipanel}

#re-plot all 3 maps simplified:

map2000 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2000_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2000_coord_diff$links)) +
  geom_point(
    data = dtcc_2000_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2000_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "pre - 2000") 

map2010 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2010_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2010_coord_diff$links)) +
  geom_point(
    data = dtcc_2010_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2010_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "2001 - 2010") 

map2020 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2020_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_2020_coord_diff$links)) +
  geom_point(
    data = dtcc_2020_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2020_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "2011 - 2020") 

#Assemble into a single multi-panel plot:
map2000 / map2010 / map2020 +
  plot_layout(ncol = 1, nrow = 3, heights = c(1, 1, 1)) +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

#save the figure 
ggsave(here("lens-results", "country_collab_decades_map.pdf"), width = 16, height = 20, units = "cm", dpi = 300, scale = 1.2)
```

## Use igraph to create collaboration networks for institutions      

Note: needs to be redone after cleaning and imputing institution data.
https://www.grid.ac/ Global Research Identifier Database (GRID) with institution names (affiliation name).

```{r collaboration networks institutions, eval = FALSE}
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
#dim(record_df_data.authors.aff) #2968

## make a subset without missing grid_id data:
record_df_data.inst <- record_df_data.authors.aff[!is.na(record_df_data.authors.aff$grid_id), ] 
#dim(record_df_data.inst) #2188 records

#using country code and institution grid.id combined as a unique identifier
record_df_data.inst$country_grid.id <- paste(record_df_data.inst$country_code, record_df_data.inst$grid_id, sep=", ")
record_df_data.inst$Author <- paste(record_df_data.inst$last_name, record_df_data.inst$initials, sep=", ")

#prepare data frame for igraph
dti <- data.frame(pub.id = record_df_data.inst$data.lens_id, Author = record_df_data.inst$Author, value = record_df_data.inst$country_grid.id)
#str(dti)

dti %>%
  inner_join(dti, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) -> g1i

#as_data_frame(g1i, what = "edges")

# plot(g1i)
# plot(g1i, edge.arrow.size=0, vertex.color="gold", vertex.size=5, 
#      vertex.frame.color="gray", vertex.label.color="black", 
#      vertex.label.cex=0.8, vertex.label.dist=2, edge.curved=0.2)

#E(g1i)$weight <- 1 #add weights
g1is <- simplify(g1i, remove.multiple = T, remove.loops = T, 
                 edge.attr.comb=list(weight="sum", "ignore") ) #simplify
plot(g1is, layout=layout_nicely, edge.arrow.size=0, vertex.color="gold", vertex.size=5, vertex.frame.color="gray", 
     vertex.label.color="black", vertex.label.cex=0.8, vertex.label.dist=2, edge.curved=0.2)
#E(g1is)
#V(g1is)

##Find cliques (complete subgraphs of an undirected graph)
# cliques(as.undirected(g1is)) # list of cliques       
# sapply(cliques(as.undirected(g1is)), length) # clique sizes
largest_cliques(as.undirected(g1is)) # clique with max number of nodes

# vcol <- rep("grey80", vcount(as.undirected(g1is)))
# vcol[unlist(largest_cliques(as.undirected(g1is)))] <- "gold"
# plot(as.undirected(g1is), vertex.label=V(g1is)$name, vertex.color=vcol)

##Community detection based on edge betweenness (Newman-Girvan)
##High-betweenness edges are removed sequentially (recalculating at each step) and the best partitioning of the network is selected.
cebi <- cluster_edge_betweenness(as.undirected(g1is)) 
#dendPlot(cebi, mode="hclust") #too dense
plot(cebi, as.undirected(g1is), layout=layout_nicely, edge.arrow.size=0.0, vertex.color="gold", vertex.size=2,
     vertex.frame.color="grey", vertex.label.color="black", vertex.label=NA)

table(membership(cebi)) #cluster 6 is largest
membership(cebi)[membership(cebi) == 6] #largest is mostly US

#more at: https://kateto.net/netscix2016.html, pretty_plots.R
```

