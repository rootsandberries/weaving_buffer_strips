---
title: "publications_LENS_igraph"
output:
  html_document:
    code_folding: hide
    toc: TRUE
    toc_float: TRUE
    toc_depth: 4
    collapsed: FALSE
    YAML: rmdformats::robobook
editor_options: 
  chunk_output_type: console
---


```{r setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#library(ggpubr)
library(tidyverse)
library(here) #use: here("subfolder", "filename")
library(httr)
library(jsonlite)
library(ggplot2)
library(ggrepel)
library(expss)
library(igraph)
library(rworldmap)
library(patchwork) 
library(fuzzyjoin)
library(Polychrome)

```

## Summary
This code follows **publications_LENS_preprocessing.Rmd** which processes the list of the 1019 included articles stored in **20201215_EGM_Net_all-articles_clean.csv** and runs a query via LENS API custom function to retrieve their detailed bibliographic information. Retrieved data is processed to remove duplicated records and false positives (e.g., errata, commentaries, etc.), resulting in 936 records. The data is stored as a hierarchical data object with multiple levels of nested data tables (**record_df**  in **LENS_dataframe.RData**). Author names and country affiliations were further cleaned for accuracy and consistency.  

This code produces collaboration plots and statistics using igraph package.


## Load data 
"20201215_EGM_Net_all-articles_clean.csv" file has all original 1019 articles, however, cleaned data frame from LENS has only 930 articles stored in "record_df_data.authors.ids_cleaned.csv". Author, country and affiliation cleaned data frames were created from LENS API records during the preprocessing step.

```{r get full list of publications, eval = TRUE}
#load(file = here("data", "LENS_dataframe_cleaned.RData")) #loads semi-cleaned LENS output from a Rdata object - "record_df"

dat <- read.csv(here("data", "20201215_EGM_Net_all-articles_clean.csv"))
dim(dat) #1019   16
#names(dat)
#hist(dat$year)


# #initial checks
# length(unique(dat$Title)) #1019
# title <- unique(dat$Title)
# length(unique(dat$DOI)) #only 184 DOI values and missing values stored as "" (change to NA later?)
# table(dat$Item_Type) #mostly articles
# hist(dat$Pub_Year, breaks = 70)
# table(dat$Manual_Tags) #stored as vectors of characters, tags separated by "; "
# #table(dat$Item_Type)["journalArticle"] # 959 journal articles

load(file = here("data", "LENS_dataframe_cleaned.RData")) #load semi-cleaned LENS output from a Rdata object record_df (list of lists)
names(record_df)
length(record_df$data.lens_id) #930
# length(record_df$data.title)
# length(record_df$data.date_published)
# length(record_df$data.fields_of_study)

record_df_930_basic <- tibble(lens_id = record_df$data.lens_id, title = record_df$data.title, year = record_df$data.year_published,  journal = record_df$data.source$title, fields = record_df$data.fields_of_study) #simplify
names(record_df_930_basic)
```

## Use igraph to create collaboration networks for authors   

```{r load  data, eval = TRUE}
#load preprocessed LENS data frame with cleaned authors names and ids
record_df_data.authors.ids <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv")) #loads cleaned authors dataframe from csv

#dim(record_df_data.authors.ids) #3453 rows
#names(record_df_data.authors.ids) #author ID is stored as "value"

#check how many authors and ids
#record_df_data.authors.ids %>% summarise(count = n_distinct(Author)) #2149
#record_df_data.authors.ids %>% summarise(count = n_distinct(value)) #2149

#check how many authors with same name but different ids
record_df_data.authors.ids %>%
    group_by(Author) %>%
    summarise(count = n_distinct(value)) %>%
    filter(count > 1) #0 - no such cases, clean data

#Load cleaned data frame with authors affiliations
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
#str(record_df_data.authors.aff)
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")
```

```{r coathorship analysis1, eval = TRUE}
#prepare data frame for igraph
dt <- data.frame(pub.id = record_df_data.authors.ids$data.lens_id, Author = record_df_data.authors.ids$Author, value = record_df_data.authors.ids$value)
#str(dt)

dt %>%
  inner_join(dt, by = "pub.id") %>%
  filter(value.x < value.y) %>%
  count(Author.x, Author.y) %>%
  graph_from_data_frame(directed = FALSE) -> g1 #with author names as vertices

# dt %>%
#   inner_join(dt, by = "pub.id") %>%
#   filter(Author.x < Author.y) %>%
#   count(value.x, value.y) %>%
#   graph_from_data_frame(directed = FALSE) -> g1 #with ids as vertices

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")

summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)

#overall graph statistics
graph.density(g1) #0.002426185 = quite sparse
transitivity(g1, type = "global") # 0.6636143 = probability that the neighbors of a node are also connected (also called the clustering coefficient)

```



## NETWORK COMPONENTS

Components are non-connected groups of authors (silos).
We want to obtain the four largest components and compare them in terms of manually assigned attributes from the original map as well as comparing author country affiliations to look for geographic aspects of the silos.

```{r extract top4 components, eval = TRUE}
#str(g1)
#comps1 <- components(g1)
#groups(comps1)

#alt way to see components:
comps2 <- decompose(g1, min.vertices=2)
sapply(comps2, gorder) #counts number of vertices of each component 
sapply(comps2, gsize) #counts number of edges of each group 
sapply(comps2, diameter) #calculates diameter of each group 


# #a series of plots by component
# sapply(decompose(g1), plot)
# sapply(decompose(g1)[2], plot) #only second one
# sapply(decompose(g1)[2], vertex_attr) 

c <- components(g1)
sort_desc(c$csize)
table(c$csize<6) #70% of components have 5 or less authors
sort_desc(c$csize)[1:4] #sizes of the top 3 components
#comp_max <- which(c$membership == which.max(c$csize)) # get the largest component group
comp_308 <- which(c$membership == which(c$csize == 308)) # get the largest component group
comp_164 <- which(c$membership == which(c$csize == 164)) # get the largest component group
comp_98 <- which(c$membership == which(c$csize == 98)) # get the largest component group
comp_57 <- which(c$membership == which(c$csize == 57)) # get the largest component group
```

## Plot author collaboration network with largest components coloured 

```{r plot collaboration network with components, eval = TRUE}

#visualize our co-authorship graph network tbnet2 using different layouts
g1_graph_lkk <- layout.kamada.kawai(g1) 
g1_graph_nicely <- layout_nicely(g1) #choose an appropriate graph layout algorithm for the graph automatically

plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA) 

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")

#Add color to largest components
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(comp_308)]$color = "red" #set nodes of component1 to green
V(g1)[names(V(g1)) %in% names(comp_164)]$color = "blue" #set nodes of component2 to blue
V(g1)[names(V(g1)) %in% names(comp_98)]$color = "green" #set nodes of component3 to red
V(g1)[names(V(g1)) %in% names(comp_57)]$color = "yellow" #set nodes of component3 to red
plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA)

summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)

```


## Plot author collaboration network coloured by author affiliation country

```{r plot collaboration network with affiliation, eval = TRUE}

## set one country per author
#prepare affiliations data of all authors (note the Author field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

#get affiliations of unique authors
record_df_data.authors.aff %>% 
  filter(Author %in% V(g1)$name)  %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code)) -> authors_all_aff #only picking first country code

#dim(authors_all_aff) #1784 (was 2879 rows - some authors are present multiple times)
length(V(g1)$name) #2084, so 300 authors have no country code
g1_Authors <- as.data.frame(V(g1)$name)
names(g1_Authors) <- "Author"
authors_all_aff <- left_join(g1_Authors, authors_all_aff, by = "Author")
str(authors_all_aff)
length(unique(authors_all_aff$country_code)) #46

g1country <- set_vertex_attr(g1, "country", index = V(g1), authors_all_aff$country_code) #use the built-in function to set_vertex_attr to country_code
#V(g1country)$country
unique(V(g1country)$country) #46


## Assign colors to main countries and use the same color palette in bar charts

#Set colors for the most frequently occuring countries
country_color_mapping <- c("CH"="#d485b2", "ES"="#FF977E","FR"="#e673d3", "GB"="#b55043", "GR"="#a34179","IT"="#e62539", "NL"="#f2b8be", "PT"="#917477", "SK"="#9c3540", "DE"="#df8461",
"FI"="#db6917", "NO"="#e69925", "SE"="#f0b660","CZ"="#702c8c", "HU"="#91218c", "RU"="#463397","TR"="#e3a9fc", "CA"="#96cde6","US"="#4a6aa1", "CO"="#6f340d", "JP"="#7f7e80","ID"="#c1c7c1", "PH"="#2b3514", "JO"="#e8e948", "NZ"="#5fa641", "AU"="#92ae31")
other_color <- "white" #Set all other countries to white

#Assign colors to country codes
authors_all_aff$country_color <- 
  ifelse(authors_all_aff$country_code %in%
          names(country_color_mapping),                
          country_color_mapping[authors_all_aff$country_code],
          other_color) #add new column, matching country_code

g1country <- set_vertex_attr(g1country, "color", index = V(g1), as.character(authors_all_aff$country_color)) #assign colors to vertices
#V(g1country)$color

par(mfrow=c(1,1), mar = c(0,0,0,0))

#Use colors in the plot:
g1country_graph_nicely <- layout_nicely(g1country) #choose an appropriate graph layout algorithm for the graph 
plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))

```

## Generate author network figures

```{r plot top4 components and countries, eval = TRUE}

pdf(here::here("plots", "Figure_1A-B.pdf"), width = 7, height = 5, pointsize = 10)
par(mfrow=c(1,2), mar = c(0,0,1,0))

V(g1)$color = "white" #set all nodes to white
V(g1)[comp_308]$color = "red" #set comp_max nodes to red
V(g1)[comp_164]$color = "blue" #set comp_max nodes to blue
V(g1)[comp_98]$color = "green" #set comp_max nodes to green
V(g1)[comp_57]$color = "yellow" #set comp_max nodes to yellow

plot(g1, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1)$color, alpha.f = .8))
text(0, 1.2, label = "A. Four largest network components", cex = 1.2)

plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))
text(0, 1.2, label = "B. Author country affiliations", cex = 1.2)

dev.off()

```

## Get author affiliations by component and generate bar plots

```{r compare top4 components authors, eval = TRUE}

#record_df_data.authors.ids_cleaned <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv"))
#str(record_df_data.authors.ids_cleaned) #this dataframe has no affiliation info 

#get affiliations of authors from  the cleaned affiliations dataframe
record_df_data.authors.aff <- read.csv(here::here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

## Which authors are represented by biggest components? - then try to connect to data on their affiliation country
#see author ids for top 4 components
dt %>% filter(Author %in% names(comp_308)) -> authors_comp_308
dt %>% filter(Author %in% names(comp_164)) -> authors_comp_164
dt %>% filter(Author %in% names(comp_98)) -> authors_comp_98
dt %>% filter(Author %in% names(comp_57)) -> authors_comp_57


## component comp_308 (nr1)

length(unique(authors_comp_308$pub.id)) #148
length(unique(authors_comp_308$Author)) #308
length(unique(authors_comp_308$value)) #308

#get publications for the component with 308 authors (component 1):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_308$pub.id)) -> authors_comp_308_pubs #publications of the authors from the component 1
#str(authors_comp_308_pubs)

# publication details for the component with 308 authors (component 1):
authors_comp_308_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_308_pubs_details

#get affiliations for authors for the component with 308 authors (component 1):
dt %>%
  filter(Author %in% unique(authors_comp_308$Author)) %>% 
  distinct(pub.id) -> authors_308_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_308_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_308$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_308_aff #sort to have most recent on top and save

#str(authors_comp_308_aff) #622 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_308_aff$Author)) #300 unique authors captured
table(authors_comp_308_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_308_oneaff

#make a barplot of country codes for the component with 308 authors (component 1):
p_countryfreq1 <- as.data.frame(table(authors_comp_308_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.9) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping) #use color scheme from network plot


## component comp_164 (component 2)

length(unique(authors_comp_164$pub.id)) #95
length(unique(authors_comp_164$Author)) #164
length(unique(authors_comp_164$value)) #164

#get publications for the component with 164 authors (component 2):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_164$pub.id)) -> authors_comp_164_pubs #publications of the authors from the component 2
#str(authors_comp_164_pubs)

# publication details for the component with 164 authors (component 2):
authors_comp_164_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_164_pubs_details

#get affiliations for authors for the component with 164 authors (component 2):
dt %>%
  filter(Author %in% unique(authors_comp_164$Author)) %>% 
  distinct(pub.id) -> authors_164_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_164_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_164$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_164_aff #sort to have most recent on top and save

#str(authors_comp_164_aff) #294 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_164_aff$Author)) #137 unique authors captured
table(authors_comp_164_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_164_oneaff

#make a barplot of country codes for the component with 164 authors (component 2):
p_countryfreq2 <- as.data.frame(table(authors_comp_164_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.6) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)


## component comp_98 (component 3)

#get publications for the component with 98 authors (component 3):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_98$pub.id)) -> authors_comp_98_pubs #publications of the authors from the component 3
#str(authors_comp_98_pubs)

# publication details for the component with 98 authors (component 3):
authors_comp_98_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_98_pubs_details

#get affiliations for authors for the component with 98 authors (component 3):
dt %>%
  filter(Author %in% unique(authors_comp_98$Author)) %>% 
  distinct(pub.id) -> authors_98_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_98_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_98$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_98_aff #sort to have most recent on top and save

#str(authors_comp_98_aff) #169 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_98_aff$Author)) #81 unique authors captured
table(authors_comp_98_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_98_oneaff

#make a barplot of country codes for the component with 98 authors (component 3):
p_countryfreq3 <- as.data.frame(table(authors_comp_98_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.4) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)


## component comp_57 (component 4)

#get publications for the component with 57 authors (component 4):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_57$pub.id)) -> authors_comp_57_pubs #publications of the authors from the component 4
#str(authors_comp_57_pubs)

# publication details for the component with 57 authors (component 4):
authors_comp_57_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_57_pubs_details

#get affiliations for authors for the component with 57 authors (component 4):
dt %>%
  filter(Author %in% unique(authors_comp_57$Author)) %>% 
  distinct(pub.id) -> authors_57_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_57_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_57$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_57_aff #sort to have most recent on top and save

#str(authors_comp_57_aff) #70 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_57_aff$Author)) #42 unique authors captured
table(authors_comp_57_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_57_oneaff

#make a barplot of country codes for the component with 57 authors (component 3):
p_countryfreq4 <- as.data.frame(table(authors_comp_57_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.06) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies") +
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)



## Assemble individual barplots into a single multi-panel plot:
p_countryfreq1 / p_countryfreq2 / p_countryfreq3 / p_countryfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1)) +
  #plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 11, face = "bold"))

g <- ggplot_build(p_countryfreq1)
unique(g$data[[1]]["fill"])


#save the figure 
ggsave(here("plots", "Figure_1C.pdf"), width = 7, height = 6.3, units = "in", dpi = 600, scale = 1)

```


## Analyze attributes of largest author components

```{r analyse top4 components, eval = TRUE}
## Which papers are represented by the largest components? - then try to connect to data on functional roles

#see publications from top 4 components
dt %>% filter(Author %in% names(comp_308)) %>% distinct(pub.id) -> authors_comp_308_pubids
dt %>% filter(Author %in% names(comp_164)) %>% distinct(pub.id) -> authors_comp_164_pubids
dt %>% filter(Author %in% names(comp_98)) %>% distinct(pub.id) -> authors_comp_98_pubids
dt %>% filter(Author %in% names(comp_57)) %>% distinct(pub.id) -> authors_comp_57_pubids

#get publication details 
record_df_930_basic %>% filter(lens_id %in% authors_comp_308_pubids$pub.id)  -> authors_comp_308_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_164_pubids$pub.id)  -> authors_comp_164_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_98_pubids$pub.id)  -> authors_comp_98_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_57_pubids$pub.id)  -> authors_comp_57_pubids_basic

authors_comp_top4_pubids_basic <- bind_rows(authors_comp_308_pubids_basic, authors_comp_164_pubids_basic, authors_comp_98_pubids_basic, authors_comp_57_pubids_basic, .id = "Comp")
#str(authors_comp_top4_pubids_basic)

#histogram of publication years
ggplot(authors_comp_top4_pubids_basic, aes(year, fill = Comp)) + geom_histogram(binwidth = 5)

#with feqpolygons for better readability
ggplot(authors_comp_top4_pubids_basic, aes(year, colour = Comp)) + geom_freqpoly(binwidth = 5)

#top ten "fields" labels for publication from this component (note these are not manual tags used in the original map)
table(unlist(authors_comp_308_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_164_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_98_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_57_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)

```

### Analyze functional roles studied of largest author components


```{r compare top4 components terms, eval = TRUE}
## use file lens_bibcouple/data/13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv - column all_outcomes_group

myroles <- read.csv(here("data", "13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv")) 
dim(myroles)
#names(myterms)
myroles$title <- str_to_lower(myroles$Title) #change to lowercase to make it easier to merge by title (using fuzzyjoin package)
myroles$all_outcomes_group <- str_to_title(myroles$all_outcomes_group) #change to titlecase to make it match with other plots made

#Fuzzy join of clusters with myroles dataset using title column
authors_comp_308_pubids_basic$title <- tolower(authors_comp_308_pubids_basic$title)

data_comp_308 <- stringdist_inner_join(authors_comp_308_pubids_basic, myroles, by = "title", max_dist = 8, distance_col = "distance")

data_comp_308_roles <- unlist(strsplit(data_comp_308$all_outcomes_group, ";"))
authors_comp_164_pubids_basic$title <- tolower(authors_comp_164_pubids_basic$title)

data_comp_164 <- stringdist_inner_join(authors_comp_164_pubids_basic, myroles, by = "title", max_dist = 8, distance_col = "distance")

data_comp_164_roles <- unlist(strsplit(data_comp_164$all_outcomes_group, ";"))
authors_comp_98_pubids_basic$title <- tolower(authors_comp_98_pubids_basic$title)

data_comp_98 <- stringdist_inner_join(authors_comp_98_pubids_basic, myroles, by = "title", max_dist = 8, distance_col = "distance")

data_comp_98_roles <- unlist(strsplit(data_comp_98$all_outcomes_group, ";"))
authors_comp_57_pubids_basic$title <- tolower(authors_comp_57_pubids_basic$title)

data_comp_57 <- stringdist_inner_join(authors_comp_57_pubids_basic, myroles, by = "title", max_dist = 8, distance_col = "distance")

data_comp_57_roles <- unlist(strsplit(data_comp_57$all_outcomes_group, ";"))

## count terms within each component and create barplots

p_wordfreq1 <- as.data.frame(table(data_comp_308_roles)) %>% #count roles and create data frame
  #top_n(10) %>% #pick top 10 roles - there are only 7 roles
  rename(Roles = data_comp_308_roles) %>% #rename column
	ggplot(aes(x = reorder(Roles,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Roles, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  geom_text(aes(label = Freq), hjust = -0.2) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq2 <- as.data.frame(table(data_comp_164_roles)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 7 terms
  rename(Roles = data_comp_164_roles) %>% #rename column
	ggplot(aes(x = reorder(Roles,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Roles, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  geom_text(aes(label = Freq), hjust = -0.2) +
  scale_y_continuous(labels=scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight=.8, face="bold")) +
  theme(legend.position="none")

p_wordfreq3 <- as.data.frame(table(data_comp_98_roles)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 6 terms!
  rename(Roles = data_comp_98_roles) %>% #rename column
  rbind(setNames(data.frame("Pollution", 0), c("Roles", "Freq"))) %>% #add 7th term with value 0
  ggplot(aes(x = reorder(Roles,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Roles, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  geom_text(aes(label = Freq), hjust = -0.2) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) + 
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq4 <- as.data.frame(table(data_comp_57_roles)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms
  rename(Roles = data_comp_57_roles) %>% #rename column
  ggplot(aes(x = reorder(Roles,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Roles, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  geom_text(aes(label = Freq), hjust = -0.2) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) + labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

#Assemble into a single multi-panel plot:
p_wordfreq1 / p_wordfreq2 / p_wordfreq3 / p_wordfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1, 1)) +
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

#save the figure 
ggsave(here("plots", "Figure_2.pdf"), width = 7, height = 5, units = "in", dpi = 600, scale = 1.5)

```



## AUTHOR CENTRALITY

```{r coathorship centrality measures, eval = TRUE}
#Calculating more centrality measures (degree, betweeness, closeness, eigenvector centrality, coreness)
metrics <- data.frame(
  deg = degree(g1),
  bet = betweenness(g1),
  clo = closeness(g1),
  eig = evcent(g1)$vector,
  cor = graph.coreness(g1)
  )

cor(metrics) #check for linear correlations
```


```{r most central authors, eval = TRUE}

#compute centrality measures for vertexes - degree (number of links to a given author)
g1_degree <- degree(g1) 
#hist(g1_degree) #a small number of high-degree vertexes - highly skewed

#plot with node colors reflecting their degree
cols_g1 <- setNames(colorRampPalette(c("white", "red"))(length(unique(g1_degree))), unique(g1_degree)) 
plot(g1, layout = g1_graph_lkk, vertex.label = NA, vertex.size = 2, vertex.color = cols_g1[degree(g1)])
#set the colours using vertex.color = cols[degree(g1_degree)]

#find authors with degree > X
authors_central <- g1_degree[g1_degree > 5] #10 people for >25, 59 for > 15, 163 for >10, 639 for >5
length(names(authors_central))


#plot central authors as red, rest as white
#comp_164 <- which(g1$membership == which(c$csize == 164)) # get the id numbers
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(authors_central)]$color = "red" #set nodes to red
plot(g1, layout = g1_graph_lkk, vertex.size = 2, vertex.label = NA)

#get publications by central authors
dt %>% 
  filter(Author %in% names(authors_central)) %>% 
  distinct(pub.id) -> authors_central_pubids

#str(authors_central_pubids)
#record_df_data.authors.ids$data.lens_id

#get details of publications of central authors
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% authors_central_pubids$pub.id) -> authors_central_pubs
#str(authors_central_pubs)
#length(unique(authors_central_pubs$Author)) #these are all authors, many are not-central

#central authors with their papers details:
authors_central_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_central_pubs_details

#authors_central_pubs_details$data.lens_id #central authors with their papers ids
length(unique(authors_central_pubs_details$data.lens_id)) # publications across all central authors

#prepare affiliations data of all authors (note the Author field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

#get affiliations of central authors
record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_central_pubs_details$data.lens_id) %>%
  filter(Author %in% names(authors_central)) -> authors_central_aff

#str(authors_central_aff) #191 rows 
unique(authors_central_aff$Author) # unique authors captured

# #count number of papers (data.title) per Author
# authors_central_aff %>% 
#   group_by(Author) %>%
#   count()
#   
# #collapse country codes
# # authors_central_aff %>% 
# #   group_by(Author) %>%
# #   summarize(country_code = paste(country_code, collapse = "; ")) 
# #only use first country code:
# authors_central_aff %>% 
#   group_by(Author) %>%
#   arrange((data.year_published)) %>%
#   summarize(country_code = first(country_code))  #only picking first one, mostly GB

#retain more columns
authors_central_aff %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code), affiliation = first(name), N_publications = n()) -> authors_central_table  #only picking first country code and adding counts of publications

authors_central_table$affiliation <- gsub(",.*", "", authors_central_table$affiliation) #truncate affiliations at first comma

#length(authors_central) #639
#dim(authors_central_table) #582
authors_central <- authors_central[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_central) == authors_central_table$Author #check if order of names is matching

#add and arrange in a data frame:
authors_central_table$Centrality <- unname(authors_central) #add a column with degrees centrality
authors_central_table$component_orig <- as.numeric(c$membership[names(authors_central)])

#check cluster numbers - for recoding to 1 2 3 4 - used below
# as.numeric(c$membership[unique(authors_central_aff$Author)]) #pick 2 5 20 51 - see below:
# which(c$csize == 308) #2
# which(c$csize == 164) #5
# which(c$csize == 98) #20
# which(c$csize == 57) #51
authors_central_table$component_nr <- case_when(authors_central_table$component_orig == 2 ~ 1,
                                         authors_central_table$component_orig == 5 ~ 2,
                                         authors_central_table$component_orig == 20 ~ 3,
                                         authors_central_table$component_orig == 51 ~ 4
                                         ) #we only assign numbers 1,2,3,4 to members of the four biggest clusters, rest is NA

#rearrange columns and sort by cluster and centrality
authors_central_table %>% 
  select(component_nr, Centrality, country_code, Author, affiliation, N_publications) %>% 
  arrange(component_nr, Centrality) %>% 
  arrange(desc(Centrality)) %>% 
  group_by(component_nr) %>%
  slice(1:10) %>%  #pick top 10 from each component
  filter(component_nr != "NA") ->  #remove "NA" component
  authors_central_table 
  #knitr::kable() %>%
  #View()
```

#AUTHOR BETWEENNESS
```{r most betweeness central authors, eval = TRUE}
g1_bet <- betweenness(g1)
hist(g1_bet) #highly skewed
authors_bet <- g1_bet[g1_bet > 1] #326 with betweenes score >1: length(names(authors_bet))
authors_bet <- authors_bet[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_bet) == authors_central_table$Author #check if order of names is matching
authors_central_table$Betweenness <- round(unname(authors_bet), 1) #add a column with degrees centrality

write.csv(authors_central_table, file = here("plots", "Table_1.csv"))

```

#Key authors and the functional roles studied
```{r key author functional roles, eval = TRUE}

#Import dataset from original systematic map containing functional roles by paper

myoutcomes <- read.csv("data/13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv")

#Merge central authors' publication dataset to functional roles dataset using a fuzzy join on title

author_outcome <- stringdist_inner_join(authors_central_pubs_details, myoutcomes, by = c("Paper_title" = "Title"), max_dist = 10, distance_col = "distance") %>% as.data.frame()
dim(author_outcome) #509

#Select only needed columns
author_outcome_df <- subset(author_outcome, select = c("Title", "Authors", "Year.x", "all_outcomes_group"))

#Separate author columns into individual rows
author_outcome_sep <- separate_rows(author_outcome_df, Authors, sep = ";") 
author_outcome_sep$Authors <- trimws(author_outcome_sep$Authors)

#Select only key authors
key_author_outcome <- author_outcome_sep %>%
  filter(Authors %in% c("Pywell, RF", "Sparks, TH", "Potts, SG", "Woodcock, BA", "Carvell, C", "Isenhart, TM", "Schultz, RC", "Helmers, MJ", "Udawatta, RP", "Anderson, SH", "Macdonald, DW", "Feber, RE", "Smith, HL", "van Lenteren, JC", "Johnson, PJ", "Reberg-Horton, C", "Moorman, CE", "Osmond, DL", "Lowrance, R", "Burchell, MR"))

#Count number of papers by each author

key_author_counts <- key_author_outcome %>% group_by(Authors) %>%
  summarize(count = n())

#Split functional role column into individual roles
key_author_outcome_sep <- separate_rows(key_author_outcome, all_outcomes_group, sep = ";")

key_author_outcome_uni <- distinct(key_author_outcome_sep)

summary_df <- key_author_outcome_uni %>%
  group_by(Authors, all_outcomes_group) %>%
  summarize(records = n()) |> arrange(Authors)


#Merge to author counts to use in proportion calculations

summary_df_pubcount <- summary_df %>%
  left_join(key_author_counts, by = "Authors")

#Add column of proportion of times functional role is studied across all author's publications

summary_df_pubcount <- summary_df_pubcount |>  mutate(prop = round(records/count *100))

#Reorder author names
summary_df_pubcount$Authors <-  factor(summary_df$Authors, levels = c("Burchell, MR", "Lowrance, R", "Anderson, SH", "Helmers, MJ", "Udawatta, RP", "Schultz, RC", "Isenhart, TM", "Osmond, DL", "Sparks, TH", "Carvell, C", "Pywell, RF", "Woodcock, BA", "Macdonald, DW", "Potts, SG", "Feber, RE", "Moorman, CE",  "Reberg-Horton, C", "Smith, HL", "Johnson, PJ",  "van Lenteren, JC"))

#Rename factors with number of publications in parentheses

levels(summary_df_pubcount$Authors) <- c("Burchell, MR (1)", "Lowrance, R (3)", "Anderson, SH (13)", "Helmers, MJ (11)", "Udawatta, RP (15)", "Schultz, RC (18)", "Isenhart, TM (15)", "Osmond, DL (3)", "Sparks, TH (12)", "Carvell, C (10)", "Pywell, RF (16)", "Woodcock, BA (14)", "Macdonald, DW (19)", "Potts, SG (13)", "Feber, RE (13)", "Moorman, CE (6)",  "Reberg-Horton, C (5)", "Smith, HL (4)", "Johnson, PJ (4)",  "van Lenteren, JC (2)")

#Plot small multiples bar graph by author
ggplot(summary_df_pubcount, aes(x = all_outcomes_group, y = prop, fill = all_outcomes_group)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ Authors, scales = "free_y") + labs(x = "",
       y = "% of publications addressing a functional role",
       fill = "") +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem functioning" = "#A6DBA0", "Human use" = "#ABD9E9", "Societal" = "#74ADD1", "Pollution" = "#9970AB", "Soil chemistry" = "#C2A5CF", "Soil physical" = "#E7D4E8")) + theme_minimal() + theme(axis.text.x = element_blank()) + scale_y_continuous(limits = c(0, 100)) +  theme(legend.position = "bottom", text = element_text(size = 8))
  
ggsave(here("plots", "Figure_3.pdf"), width = 7, height = 6, units = "in", dpi = 600, scale = 1)


```

## Collaboration over time Supplemental Figures

```{r collaboration networks country prep}

record_df_data.authors.aff <- read.csv(here::here("data", "record_df_data.authors.aff_cleaned.csv"))
#names(record_df_data.authors.aff)

record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep=", ") #this would need some extra cleaning to perfectly match Author field in record_df_data.authors.ids

#remove records with missing country code
table(is_na(record_df_data.authors.aff$country_code))
record_df_data.authors.aff %>% 
  drop_na(country_code) -> record_df_data.authors.aff
table(is_na(record_df_data.authors.aff$country_code))

#prepare data frame for igraph
dtc <- data.frame(pub.id = record_df_data.authors.aff$data.lens_id, Author = record_df_data.authors.aff$Author, value = record_df_data.authors.aff$country_code)
#str(dtc)
```

Make series of graph by decade

```{r collaboration networks country decade}
#names(record_df_data.authors.aff)
hist(record_df_data.authors.aff$data.year_published)
hist(dtc$data.year_published)

## before 2000
record_df_data.authors.aff %>% 
  filter(data.year_published > 1950 & data.year_published <= 2000) -> record_df_data.authors.aff_2000
dtc_2000 <- data.frame(pub.id = record_df_data.authors.aff_2000$data.lens_id, Author = record_df_data.authors.aff_2000$Author, value = record_df_data.authors.aff_2000$country_code)
dtc_2000 %>%
  inner_join(dtc_2000, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2000 #simplify
deg_2000 <- degree(g1cs_2000, mode = "all") # Count the number of degree for each node
cebc_2000 <- cluster_edge_betweenness(as.undirected(g1cs_2000)) 
#dendPlot(cebi, mode="hclust") #using deg for sizing the vertices
p_2000 <- plot(cebc_2000, as.undirected(g1cs_2000), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2000,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, 
     main = "pre-2001")

## decade 2001 - 2010
record_df_data.authors.aff %>% 
  filter(data.year_published >= 2000 & data.year_published <= 2010) -> record_df_data.authors.aff_2010
dtc_2010 <- data.frame(pub.id = record_df_data.authors.aff_2010$data.lens_id, Author = record_df_data.authors.aff_2010$Author, value = record_df_data.authors.aff_2010$country_code)
dtc_2010 %>%
  inner_join(dtc_2010, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2010 #simplify
deg_2010 <- degree(g1cs_2010, mode = "all") # Count the number of degree for each node
cebc_2010 <- cluster_edge_betweenness(as.undirected(g1cs_2010)) 
#dendPlot(cebi, mode="hclust") #using deg fo sizing the vertices
p_2010 <- plot(cebc_2010, as.undirected(g1cs_2010), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2010,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA,
     main = "2001-2010") 

## decade 2011 - 2020
record_df_data.authors.aff %>% 
  filter(data.year_published >= 2010) -> record_df_data.authors.aff_2020
dtc_2020 <- data.frame(pub.id = record_df_data.authors.aff_2020$data.lens_id, Author = record_df_data.authors.aff_2020$Author, value = record_df_data.authors.aff_2020$country_code)
dtc_2020 %>%
  inner_join(dtc_2020, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) %>%
  graph_from_data_frame(directed = FALSE) %>% 
  simplify(remove.multiple = T, remove.loops = T, 
                 edge.attr.comb = list(weight = "sum", "ignore") ) -> g1cs_2020 #simplify
deg_2020 <- degree(g1cs_2020, mode = "all") # Count the number of degree for each node
cebc_2020 <- cluster_edge_betweenness(as.undirected(g1cs_2020)) 
p_2020 <- plot(cebc_2020, as.undirected(g1cs_2020), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = NA, vertex.size = deg_2020,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA,
     main = "2011-2020")

```

Assemble into a multi-panel plot

```{r collaboration networks country decades multipanel}

pdf(here("plots", "Fig_S2D.pdf"), width = 7, heigh = 4, pointsize = 12)

par(mfrow=c(1,3), mar = c(0,0,1,0))
#par(mfrow=c(1,1), mar = c(0,0,0,0))

p_2000 <- plot(cebc_2000, as.undirected(g1cs_2000), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2000*2, edge.color = "grey",
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "pre-2001")

p_2010 <- plot(cebc_2010, as.undirected(g1cs_2010), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "gold", vertex.size = deg_2010*2,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "2001 - 2010") 

p_2020 <- plot(cebc_2020, as.undirected(g1cs_2020), layout = layout_nicely, 
     edge.arrow.size = 0.0, vertex.color = "white", vertex.size = deg_2020*2,
     vertex.frame.color = "grey", vertex.label.color = "black", 
     mark.col = NA, mark.border = NA, col = NA, 
     main = "2011 - 2020")

dev.off()

```


Plot country collaboration on a map

```{r collaboration networks country map - all years}

#worldmap <- getMap() #use data from package rworldmap
worldmap <- getMap()[-which(getMap()$ADMIN=="Antarctica"),] #use data from package rworldmap and remove Antarctica 
#worldmap <- spTransform(worldmap, CRS=CRS("+proj=robin +ellps=WGS84")) #transform to robin for the Robinson projection - messess up coordinates for the lines and points, because the country centroid coordinate used for plotting does not get transformed - needs rgdal package - install.packages("rgdal")
worldmap_names <- select(as.data.frame(worldmap), ISO_A2) #extract country codes
worldmap_names <- levels(worldmap_names$ISO_A2) #make names into a character vector

dtc %>%
  inner_join(dtc, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc

names(dtcc) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_coord <- dtcc %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_coord_diff <- filter(dtcc_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_coord_same <- filter(dtcc_coord, country.x == country.y) # points with the same countries - use for points

fig_map_allyears <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "yellow", alpha = 0.5, size = log10(dtcc_coord_diff$links)) +
  geom_point(
    data = dtcc_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations", caption = "circles = national collaborations (log10), lines = international coollaborations") 
```


Plot by decade and assemble into a multi-panel plot map 

```{r collaboration networks country map - decades}

#worldmap <- getMap() #use data from package rworldmap
worldmap <- getMap()[-which(getMap()$ADMIN=="Antarctica"),] #use data from package rworldmap and remove Antarctica 
#worldmap <- spTransform(worldmap, CRS=CRS("+proj=robin +ellps=WGS84")) #transform to robin for the Robinson projection - messess up coordinates for the lines and points, because the country centroid coordinate used for plotting does not get transformed
worldmap_names <- select(as.data.frame(worldmap), ISO_A2) #extract country codes
worldmap_names <- levels(worldmap_names$ISO_A2) #make names into a character vector

## before 2000
record_df_data.authors.aff %>% 
  filter(data.year_published > 1950 & data.year_published <= 2000) -> record_df_data.authors.aff_2000

dtc_2000 <- data.frame(pub.id = record_df_data.authors.aff_2000$data.lens_id, Author = record_df_data.authors.aff_2000$Author, value = record_df_data.authors.aff_2000$country_code)

dtc_2000 %>%
  inner_join(dtc_2000, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2000

names(dtcc_2000) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2000_coord <- dtcc_2000 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2000_coord_diff <- filter(dtcc_2000_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2000_coord_same <- filter(dtcc_2000_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2000 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2000_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2000_coord_diff$links)) +
  geom_point(
    data = dtcc_2000_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2000_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations pre-2000", caption = "circles = national collaborations (log10), lines = international coollaborations") 

## decade 2000 - 2010
record_df_data.authors.aff %>% 
  filter(data.year_published > 2000 & data.year_published <= 2010) -> record_df_data.authors.aff_2010
dtc_2010 <- data.frame(pub.id = record_df_data.authors.aff_2010$data.lens_id, Author = record_df_data.authors.aff_2010$Author, value = record_df_data.authors.aff_2010$country_code)

dtc_2010 %>%
  inner_join(dtc_2010, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2010

names(dtcc_2010) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2010_coord <- dtcc_2010 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2010_coord_diff <- filter(dtcc_2010_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2010_coord_same <- filter(dtcc_2010_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2010 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2010_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2010_coord_diff$links)) +
  geom_point(
    data = dtcc_2010_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2010_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations 2000 - 2010", caption = "circles = national collaborations (log10), lines = international coollaborations") 


## decade 2010 - 2020
record_df_data.authors.aff %>% 
  filter(data.year_published > 2010 & data.year_published <= 2020) -> record_df_data.authors.aff_2020
dtc_2020
dtc_2020 <- data.frame(pub.id = record_df_data.authors.aff_2020$data.lens_id, Author = record_df_data.authors.aff_2020$Author, value = record_df_data.authors.aff_2020$country_code)

dtc_2020 %>%
  inner_join(dtc_2020, by = "pub.id") %>%
  filter(Author.x < Author.y) %>%
  count(value.x, value.y) -> dtcc_2020

names(dtcc_2020) <- c("country.x", "country.y", "links")

## Add latitude and longitude to each country 
dtcc_2020_coord <- dtcc_2020 %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.x" = "ISO_A2")) %>%
  left_join(select(as.data.frame(worldmap), ISO_A2, LON, LAT),
             by = c("country.y" = "ISO_A2"))

## Split int subsets for plotting lines and circles separately
dtcc_2020_coord_diff <- filter(dtcc_2020_coord, country.x != country.y) #end points must not be identical for connecting lines
dtcc_2020_coord_same <- filter(dtcc_2020_coord, country.x == country.y) # points with the same countries - use for points

fig_map_2020 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2020_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2020_coord_diff$links)) +
  geom_point(
    data = dtcc_2020_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2020_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Country-level collaborations 2010 - 2020", caption = "circles = national collaborations (log10), lines = international coollaborations") 

```

Assemble into a single multi-panel plot

```{r collaboration map country decades multipanel}

#re-plot all 3 maps simplified:

map2000 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2000_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2000_coord_diff$links)) +
  geom_point(
    data = dtcc_2000_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2000_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "pre - 2000") 

map2010 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2010_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2010_coord_diff$links)) +
  geom_point(
    data = dtcc_2010_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2010_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "2001 - 2010") 

map2020 <- ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = dtcc_2020_coord_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = NULL, colour = "darkred", alpha = 0.5, size = log10(dtcc_2020_coord_diff$links)) +
  geom_point(
    data = dtcc_2020_coord_same,
    aes(LON.x, LAT.x, color = "orange"), size = log10(dtcc_2020_coord_same$links),
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  theme_void() +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5), plot.title = element_text(hjust = 0.5)) +
  labs(title = "2011 - 2020") 

#Assemble into a single multi-panel plot:
map2000 / map2010 / map2020 +
  plot_layout(ncol = 1, nrow = 3, heights = c(1, 1, 1)) +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 12, face = "bold"))

#save the figure 
ggsave(here("plots", "Figure_S2A-C.pdf"), width = 7, height = 10, units = "in", dpi = 600, scale = 1.2)
```


## Co-authorship network summary:    
Preproccessed dataframe containing 930 records was used to create co-authorship networks. Basic network statistics were calculated. These plots were generated with author country affiliations indicated and the largest four components were further analyzed for functional roles studied. Key authors by centrality and betweenness centrality were ranked and functional roles studied were assessed.  
