---
title: "publications_LENS_igraph"
output:
  html_document:
    code_folding: hide
    toc: TRUE
    toc_float: TRUE
    toc_depth: 4
    collapsed: FALSE
    YAML: rmdformats::robobook
editor_options: 
  chunk_output_type: console
---


```{r setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#library(ggpubr)
library(tidyverse)
library(here) #use: here("subfolder", "filename")
library(httr)
library(jsonlite)
library(ggplot2)
library(ggrepel)
library(expss)
library(igraph)
library(rworldmap)
library(patchwork) 
library(fuzzyjoin)
library(Polychrome)

```

## Summary
This code follows **publications_LENS_preprocessing.Rmd** which processes the list of the 1019 included articles stored in **20201215_EGM_Net_all-articles_clean.csv** and runs a query via LENS API custom function to retrieve their detailed bibliographic information. Retrieved data is processed to remove duplicated records and false positives (e.g., errata, commentarties, etc.), resulting in 936 records. The data is stored as a hierarchical data object with multiple levels of nested data tables (**record_df**  in **LENS_dataframe.RData**). Author names and country affiliaitions were further cleaned for accuracy and consistency.  

This code produces collaboration plots and statistics using igraph package.


## Load data 
"20201215_EGM_Net_all-articles_clean.csv" file has all original 1019 articles, however, cleaned data frame from LENS has only 930 articles stored in "record_df_data.authors.ids_cleaned.csv". Author, country and affiliation cleaned data frames were created from LENS API records during the preprocessing step.

```{r get full list of publications, eval = TRUE}
#load(file = here("data", "LENS_dataframe_cleaned.RData")) #loads semi-cleaned LENS output from a Rdata object - "record_df"

dat <- read.csv(here("data", "20201215_EGM_Net_all-articles_clean.csv"))
dim(dat) #1019   16
#names(dat)
#hist(dat$year)


# #initial checks
# length(unique(dat$Title)) #1019
# title <- unique(dat$Title)
# length(unique(dat$DOI)) #only 184 DOI values and missing values stored as "" (change to NA later?)
# table(dat$Item_Type) #mostly articles
# hist(dat$Pub_Year, breaks = 70)
# table(dat$Manual_Tags) #stored as vectors of characters, tags separated by "; "
# #table(dat$Item_Type)["journalArticle"] # 959 journal articles

load(file = here("data", "LENS_dataframe_cleaned.RData")) #load semi-cleaned LENS output from a Rdata object record_df (list of lists)
names(record_df)
length(record_df$data.lens_id) #930
# length(record_df$data.title)
# length(record_df$data.date_published)
# length(record_df$data.fields_of_study)

record_df_930_basic <- tibble(lens_id = record_df$data.lens_id, title = record_df$data.title, year = record_df$data.year_published,  journal = record_df$data.source$title, fields = record_df$data.fields_of_study) #simplify
names(record_df_930_basic)
```

## Use igraph to create collaboration networks for authors   

```{r load  data, eval = TRUE}
#load preprocessed LENS data frame with cleaned authors names and ids
record_df_data.authors.ids <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv")) #loads cleaned authors dataframe from csv

#dim(record_df_data.authors.ids) #3453 rows
#names(record_df_data.authors.ids) #author ID is stored as "value"

#check how many authors and ids
#record_df_data.authors.ids %>% summarise(count = n_distinct(Author)) #2149
#record_df_data.authors.ids %>% summarise(count = n_distinct(value)) #2149

#check how many authors with same name but different ids
record_df_data.authors.ids %>%
    group_by(Author) %>%
    summarise(count = n_distinct(value)) %>%
    filter(count > 1) #0 - no such cases, clean data

#Load cleaned data frame with authors affiliations
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
#str(record_df_data.authors.aff)
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")
```

```{r coathorship analysis1, eval = TRUE}
#prepare data frame for igraph
dt <- data.frame(pub.id = record_df_data.authors.ids$data.lens_id, Author = record_df_data.authors.ids$Author, value = record_df_data.authors.ids$value)
#str(dt)

dt %>%
  inner_join(dt, by = "pub.id") %>%
  filter(value.x < value.y) %>%
  count(Author.x, Author.y) %>%
  graph_from_data_frame(directed = FALSE) -> g1 #with author names as vertices

# dt %>%
#   inner_join(dt, by = "pub.id") %>%
#   filter(Author.x < Author.y) %>%
#   count(value.x, value.y) %>%
#   graph_from_data_frame(directed = FALSE) -> g1 #with ids as vertices

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")

summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)

#overall graph statistics
graph.density(g1) #0.002426185 = quite sparse
transitivity(g1, type = "global") # 0.6636143 = probability that the neighbors of a node are also connected (also called the clustering coefficient)

```



## NETWORK COMPONENTS

Components are non-connected groups of authors (silos).
We want to obtain the four largest components and compare them in terms of manually assigned attributes from the original map as well as comparing author country affiliations to look for geographic aspects of the silos.

```{r extract top4 components, eval = TRUE}
#str(g1)
#comps1 <- components(g1)
#groups(comps1)

#alt way to see components:
comps2 <- decompose(g1, min.vertices=2)
sapply(comps2, gorder) #counts number of vertices of each component 
sapply(comps2, gsize) #counts number of edges of each group 
sapply(comps2, diameter) #calculates diameter of each group 


# #a series of plots by component
# sapply(decompose(g1), plot)
# sapply(decompose(g1)[2], plot) #only second one
# sapply(decompose(g1)[2], vertex_attr) 

c <- components(g1)
sort_desc(c$csize)
table(c$csize<6) #70% of components have 5 or less authors
sort_desc(c$csize)[1:4] #sizes of the top 3 components
#comp_max <- which(c$membership == which.max(c$csize)) # get the largest component group
comp_308 <- which(c$membership == which(c$csize == 308)) # get the largest component group
comp_164 <- which(c$membership == which(c$csize == 164)) # get the largest component group
comp_98 <- which(c$membership == which(c$csize == 98)) # get the largest component group
comp_57 <- which(c$membership == which(c$csize == 57)) # get the largest component group
```

## Plot author collaboration network with largest components coloured 

```{r plot collaboration network with components, eval = TRUE}

#visualize our co-authorship graph network tbnet2 using different layouts
g1_graph_lkk <- layout.kamada.kawai(g1) 
g1_graph_nicely <- layout_nicely(g1) #choose an appropriate graph layout algorithm for the graph automatically

plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA) 

#see components of the igraph object
# E(g1)
# V(g1)
# g1[]
# edge_attr(g1)
# vertex_attr(g1)
# as_data_frame(g1, what = "edges")

#Add color to largest components
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(comp_308)]$color = "red" #set nodes of component1 to green
V(g1)[names(V(g1)) %in% names(comp_164)]$color = "blue" #set nodes of component2 to blue
V(g1)[names(V(g1)) %in% names(comp_98)]$color = "green" #set nodes of component3 to red
V(g1)[names(V(g1)) %in% names(comp_57)]$color = "yellow" #set nodes of component3 to red
plot(g1, layout = g1_graph_nicely, vertex.size = 2, vertex.label = NA)

summary(g1) #UN-- 2084 5266 -- + attr: name (v/c), n (e/n) 
#an undirected multigraph (parallel edges) with 2084 authors and 5266 scientific collaborations. Each node (author) in the network has 1 attribute: name. Each edge has 1 attributes: n (collaborations).
#get.edgelist(g1)

```


## Plot author collaboration network coloured by author affiliation country

```{r plot collaboration network with affiliation, eval = TRUE}

## set one country per author
#prepare affiliations data of all authors (note the Author field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

#get affiliations of unique authors
record_df_data.authors.aff %>% 
  filter(Author %in% V(g1)$name)  %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code)) -> authors_all_aff #only picking first country code

#dim(authors_all_aff) #1784 (was 2879 rows - some authors are present multiple times)
length(V(g1)$name) #2084, so 300 authors have no country code
g1_Authors <- as.data.frame(V(g1)$name)
names(g1_Authors) <- "Author"
authors_all_aff <- left_join(g1_Authors, authors_all_aff, by = "Author")
str(authors_all_aff)
length(unique(authors_all_aff$country_code))

g1country <- set_vertex_attr(g1, "country", index = V(g1), authors_all_aff$country_code) #use the built-in function to set_vertex_attr to country_code
#V(g1country)$country
unique(V(g1country)$country)


## Assign colors to main countries and use the same color palette in bar charts

#Set colors for the most frequently occuring countries
country_color_mapping <- c("AU" = "gray87", "CA" = "#1d1d1d", "CH" = "#ebce2b", "CO" = "#702c8c", "CZ" = "#db6917", "DE" = "#463397", "ES" = "#91218c", "FI" = "#c0bd7f", "FR" = "#df8461", "GB" = "#5fa641", "GR" = "#96cde6", "HU" = "#0B31A5", "ID" = "#d32b1e", "IT" = "#d485b2", "JO" = "#e1a11a", "JP" = "#ba1c30", "NL" = "#7f7e80","NO" = "#7e1510", "NZ" = "#92ae31", "PH" = "#6f340d", "PT" = "#1DD5EE", "RU" = "#e8e948", "SE" = "#2b3514", "SK" = "#FF977E", "TR" = "#CCAA14", "US"= "#4277b6")
other_color <- "white" #Set all other countries to white

#Assign colors to country codes
authors_all_aff$country_color <- 
  ifelse(authors_all_aff$country_code %in%
          names(country_color_mapping),                
          country_color_mapping2[authors_all_aff$country_code],
          other_color) #add new column, matching country_code

g1country <- set_vertex_attr(g1country, "color", index = V(g1), as.character(authors_all_aff$country_color)) #assign colors to vertices
#V(g1country)$color

par(mfrow=c(1,1), mar = c(0,0,0,0))

#Use colors in the plot:
g1country_graph_nicely <- layout_nicely(g1country) #choose an appropriate graph layout algorithm for the graph 
plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))

```

## Generate author network figures

```{r plot top4 components and countries, eval = TRUE}

pdf(here("plots", "Fig1B_author_components_countries.pdf"), width = 16, height = 10, pointsize = 16)
par(mfrow=c(1,2), mar = c(0,0,1,0))

V(g1)$color = "white" #set all nodes to white
V(g1)[comp_308]$color = "red" #set comp_max nodes to red
V(g1)[comp_164]$color = "blue" #set comp_max nodes to blue
V(g1)[comp_98]$color = "green" #set comp_max nodes to green
V(g1)[comp_57]$color = "yellow" #set comp_max nodes to yellow

plot(g1, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1)$color, alpha.f = .8))
text(0, 1.2, label = "A. Four largest network components", cex = 1.5)

plot(g1country, layout = g1_graph_nicely, vertex.size = 5, vertex.label = NA, vertex.color = adjustcolor(V(g1country)$color, alpha.f = .8))
text(0, 1.2, label = "B. Author country affiliations", cex = 1.5)

dev.off()

```

## Get author affiliations by component and generate bar plots

```{r compare top4 components authors, eval = TRUE}

#record_df_data.authors.ids_cleaned <- read.csv(here("data", "record_df_data.authors.ids_cleaned.csv"))
#str(record_df_data.authors.ids_cleaned) #this dataframe has no affiliation info 

#get affiliations of authors from  the cleaned affiliations dataframe
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

## Which authors are represented by biggest components? - then try to connect to data on their affiliation country
#see author ids for top 3 components
dt %>% filter(Author %in% names(comp_308)) -> authors_comp_308
dt %>% filter(Author %in% names(comp_164)) -> authors_comp_164
dt %>% filter(Author %in% names(comp_98)) -> authors_comp_98
dt %>% filter(Author %in% names(comp_57)) -> authors_comp_57


## component comp_308 (nr1)

length(unique(authors_comp_308$pub.id)) #148
length(unique(authors_comp_308$Author)) #308
length(unique(authors_comp_308$value)) #308

#get publications for the component with 308 authors (component 1):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_308$pub.id)) -> authors_comp_308_pubs #publications of the authors from the component 1
#str(authors_comp_308_pubs)

# publication details for the component with 308 authors (component 1):
authors_comp_308_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_308_pubs_details

#get affiliations for authors for the component with 308 authors (component 1):
dt %>%
  filter(Author %in% unique(authors_comp_308$Author)) %>% 
  distinct(pub.id) -> authors_308_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_308_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_308$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_308_aff #sort to have most recent on top and save

#str(authors_comp_308_aff) #622 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_308_aff$Author)) #300 unique authors captured
table(authors_comp_308_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 308 authors (component 1):
authors_comp_308_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_308_oneaff

#make a barplot of country codes for the component with 308 authors (component 1):
p_countryfreq1 <- as.data.frame(table(authors_comp_308_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.9) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping) #use color scheme from network plot


## component comp_164 (component 2)

length(unique(authors_comp_164$pub.id)) #95
length(unique(authors_comp_164$Author)) #164
length(unique(authors_comp_164$value)) #164

#get publications for the component with 164 authors (component 2):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_164$pub.id)) -> authors_comp_164_pubs #publications of the authors from the component 2
#str(authors_comp_164_pubs)

# publication details for the component with 164 authors (component 2):
authors_comp_164_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_164_pubs_details

#get affiliations for authors for the component with 164 authors (component 2):
dt %>%
  filter(Author %in% unique(authors_comp_164$Author)) %>% 
  distinct(pub.id) -> authors_164_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_164_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_164$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_164_aff #sort to have most recent on top and save

#str(authors_comp_164_aff) #294 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_164_aff$Author)) #137 unique authors captured
table(authors_comp_164_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 164 authors (component 2):
authors_comp_164_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_164_oneaff

#make a barplot of country codes for the component with 164 authors (component 2):
p_countryfreq2 <- as.data.frame(table(authors_comp_164_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.6) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)


## component comp_98 (component 3)

#get publications for the component with 98 authors (component 3):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_98$pub.id)) -> authors_comp_98_pubs #publications of the authors from the component 3
#str(authors_comp_98_pubs)

# publication details for the component with 98 authors (component 3):
authors_comp_98_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_98_pubs_details

#get affiliations for authors for the component with 98 authors (component 3):
dt %>%
  filter(Author %in% unique(authors_comp_98$Author)) %>% 
  distinct(pub.id) -> authors_98_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_98_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_98$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_98_aff #sort to have most recent on top and save

#str(authors_comp_98_aff) #169 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_98_aff$Author)) #81 unique authors captured
table(authors_comp_98_aff$country_code) #mostly GB (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 98 authors (component 3):
authors_comp_98_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_98_oneaff

#make a barplot of country codes for the component with 98 authors (component 3):
p_countryfreq3 <- as.data.frame(table(authors_comp_98_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.4) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)


## component comp_57 (component 4)

#get publications for the component with 57 authors (component 4):
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% unique(authors_comp_57$pub.id)) -> authors_comp_57_pubs #publications of the authors from the component 4
#str(authors_comp_57_pubs)

# publication details for the component with 57 authors (component 4):
authors_comp_57_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_comp_57_pubs_details

#get affiliations for authors for the component with 57 authors (component 4):
dt %>%
  filter(Author %in% unique(authors_comp_57$Author)) %>% 
  distinct(pub.id) -> authors_57_pubids

record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_comp_57_pubs_details$data.lens_id) %>% #match by publication id
  filter(Author %in% unique(authors_comp_57$Author)) %>% #match by author name
  arrange(-data.year_published) -> authors_comp_57_aff #sort to have most recent on top and save

#str(authors_comp_57_aff) #70 rows - same authors appearing multiple times in different publications
length(unique(authors_comp_57_aff$Author)) #42 unique authors captured
table(authors_comp_57_aff$country_code) #mostly US (but not taking into account that same authors appear multiple times)

#show collapsed country codes for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = paste(country_code, collapse = "; ")) 

#only keep the first listed country code and retain more columns for the component with 57 authors (component 4):
authors_comp_57_aff %>% 
  group_by(Author) %>%
  summarize(country_code = first(country_code), affiliation = first(name)) -> authors_comp_57_oneaff

#make a barplot of country codes for the component with 57 authors (component 3):
p_countryfreq4 <- as.data.frame(table(authors_comp_57_oneaff$country_code)) %>% #count country codes and create a data frame
  rename(Codes = Var1) %>% #rename column
  ggplot(aes(x = reorder(Codes,(Freq)), y =  (Freq)/sum(Freq), fill = Codes)) + 
  geom_bar(stat = 'identity', width = 0.06) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 11) +
  labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies") +
  theme(plot.title = element_text(lineheight = .8, face = "bold")) +
  theme(legend.position = "none") +
  scale_fill_manual(values = country_color_mapping)



## Assemble individual barplots into a single multi-panel plot:
p_countryfreq1 / p_countryfreq2 / p_countryfreq3 / p_countryfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1)) +
  #plot_annotation(tag_levels = "A") &
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 11, face = "bold"))

g <- ggplot_build(p_countryfreq1)
unique(g$data[[1]]["fill"])


#save the figure 
ggsave(here("plots", "Fig1C_components_countries_bar.pdf"), width = 14, height = 12, units = "cm", dpi = 300, scale = 2)

```


## Analyze attributes of largest author components

```{r analyse top4 components, eval = TRUE}
## Which papers are represented by the largest components? - then try to connect to data on functional roles

#see publications from top 4 components
dt %>% filter(Author %in% names(comp_308)) %>% distinct(pub.id) -> authors_comp_308_pubids
dt %>% filter(Author %in% names(comp_164)) %>% distinct(pub.id) -> authors_comp_164_pubids
dt %>% filter(Author %in% names(comp_98)) %>% distinct(pub.id) -> authors_comp_98_pubids
dt %>% filter(Author %in% names(comp_57)) %>% distinct(pub.id) -> authors_comp_57_pubids

#get publication details 
record_df_930_basic %>% filter(lens_id %in% authors_comp_308_pubids$pub.id)  -> authors_comp_308_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_164_pubids$pub.id)  -> authors_comp_164_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_98_pubids$pub.id)  -> authors_comp_98_pubids_basic
record_df_930_basic %>% filter(lens_id %in% authors_comp_57_pubids$pub.id)  -> authors_comp_57_pubids_basic

authors_comp_top4_pubids_basic <- bind_rows(authors_comp_308_pubids_basic, authors_comp_164_pubids_basic, authors_comp_98_pubids_basic, authors_comp_57_pubids_basic, .id = "Comp")
#str(authors_comp_top4_pubids_basic)

#histogram of publication years
ggplot(authors_comp_top4_pubids_basic, aes(year, fill = Comp)) + geom_histogram(binwidth = 5)

#with feqpolygons for better readability
ggplot(authors_comp_top4_pubids_basic, aes(year, colour = Comp)) + geom_freqpoly(binwidth = 5)

#top ten "fields" labels for publication from this component (note these are not manual tags used in the original map)
table(unlist(authors_comp_308_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_164_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_98_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)
table(unlist(authors_comp_57_pubids_basic$fields)) %>% as.data.frame() %>% arrange(desc(Freq)) %>% top_n(10)

```


```{r compare top4 components terms, eval = TRUE}
## use file lens_bibcouple/data/13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv - column all_outcomes_group

myterms <- read.csv(here("data", "13750-2018-126-MOESM6-ESM-dedup-1019-outcome.csv")) #Subset of original map data containing vegetated strips terms
dim(myterms)
#names(myterms)
myterms$title <- str_to_lower(myterms$Title) #change to lowercase to make it easier to merge by title (using fuzzyjoin package)
myterms$all_outcomes_group <- str_to_title(myterms$all_outcomes_group) #change to titlecase to make it match with other plots made

#Fuzzy join of clusters with myterms dataset using title column
authors_comp_308_pubids_basic$title <- tolower(authors_comp_308_pubids_basic$title)

data_comp_308 <- stringdist_inner_join(authors_comp_308_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")

data_comp_308_terms <- unlist(strsplit(data_comp_308$all_outcomes_group, ";"))
authors_comp_164_pubids_basic$title <- tolower(authors_comp_164_pubids_basic$title)

data_comp_164 <- stringdist_inner_join(authors_comp_164_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")

data_comp_164_terms <- unlist(strsplit(data_comp_164$all_outcomes_group, ";"))
authors_comp_98_pubids_basic$title <- tolower(authors_comp_98_pubids_basic$title)

data_comp_98 <- stringdist_inner_join(authors_comp_98_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")

data_comp_98_terms <- unlist(strsplit(data_comp_98$all_outcomes_group, ";"))
authors_comp_57_pubids_basic$title <- tolower(authors_comp_57_pubids_basic$title)

data_comp_57 <- stringdist_inner_join(authors_comp_57_pubids_basic, myterms, by = "title", max_dist = 8, distance_col = "distance")

data_comp_57_terms <- unlist(strsplit(data_comp_57$all_outcomes_group, ";"))

## count terms within each component and create barplots

p_wordfreq1 <- as.data.frame(table(data_comp_308_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 7 terms!
  rename(Terms = data_comp_308_terms) %>% #rename column
	ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 1", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq2 <- as.data.frame(table(data_comp_164_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 7 terms!
  rename(Terms = data_comp_164_terms) %>% #rename column
	ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels=scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 2", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight=.8, face="bold")) +
  theme(legend.position="none")

p_wordfreq3 <- as.data.frame(table(data_comp_98_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms - there are only 6 terms!
  rename(Terms = data_comp_98_terms) %>% #rename column
  rbind(setNames(data.frame("Pollution", 0), c("Terms", "Freq"))) %>% #add 7th term with value 0
  ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) + 
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) +
  labs(title = "Component 3", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

p_wordfreq4 <- as.data.frame(table(data_comp_57_terms)) %>% #count terms and create data frame
  #top_n(10) %>% #pick top 10 terms
  rename(Terms = data_comp_57_terms) %>% #rename column
  ggplot(aes(x = reorder(Terms,(Freq)), y =  (Freq)/sum(Freq), fill = factor(Terms, levels = c("Soil Physical", "Soil Chemistry", "Pollution", "Recreation", "Societal", "Human Use", "Ecosystem Functioning", "Biodiversity")))) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  coord_flip() +
  theme_classic(base_size = 12) +
  scale_fill_manual(values = c("Biodiversity" = "#5AAE61", "Ecosystem Functioning" = "#A6DBA0", "Human Use" = "#ABD9E9", "Societal" = "#74ADD1", "Recreation" = "#4575B4", "Pollution" = "#9970AB", "Soil Chemistry" = "#C2A5CF", "Soil Physical" = "#E7D4E8")) + labs(title = "Component 4", 
       x = NULL, 
       y = "relative frequencies")+
  theme(plot.title = element_text(lineheight = .8, face="bold")) +
  theme(legend.position="none")

#Assemble into a single multi-panel plot:
p_wordfreq1 / p_wordfreq2 / p_wordfreq3 / p_wordfreq4 +
  plot_layout(ncol = 2, nrow = 2, widths = c(1, 1, 1, 1)) +
  theme(plot.tag.position = c(0, 0.98), plot.tag = element_text(size = 14, face = "bold"))

#save the figure 
ggsave(here("plots", "components_top4_outcomes.pdf"), width = 16, height = 8, units = "cm", dpi = 300, scale = 2)

```



## AUTHOR CENTRALITY

```{r coathorship centrality measures, eval = TRUE}
#Calculating more centrality measures (degree, betweeness, closeness, eigenvector centrality, coreness)
metrics <- data.frame(
  deg = degree(g1),
  bet = betweenness(g1),
  clo = closeness(g1),
  eig = evcent(g1)$vector,
  cor = graph.coreness(g1)
  )

cor(metrics) #check for linear correlations
```


```{r most central authors, eval = TRUE}

#compute centrality measures for vertexes - degree (number of links to a given author)
g1_degree <- degree(g1) 
#hist(g1_degree) #a small number of high-degree vertexes - highly skewed

#plot with node colors reflecting their degree
cols_g1 <- setNames(colorRampPalette(c("white", "red"))(length(unique(g1_degree))), unique(g1_degree)) 
plot(g1, layout = g1_graph_lkk, vertex.label = NA, vertex.size = 2, vertex.color = cols_g1[degree(g1)])
#set the colours using vertex.color = cols[degree(g1_degree)]

#find authors with degree > X
authors_central <- g1_degree[g1_degree > 5] #10 people for >25, 59 for > 15, 163 for >10, 639 for >5
length(names(authors_central))


#plot central authors as red, rest as white
#comp_164 <- which(g1$membership == which(c$csize == 164)) # get the id numbers
V(g1)$color = "white" #set all nodes to white
V(g1)[names(V(g1)) %in% names(authors_central)]$color = "red" #set nodes to red
plot(g1, layout = g1_graph_lkk, vertex.size = 2, vertex.label = NA)

#get publications by central authors
dt %>% 
  filter(Author %in% names(authors_central)) %>% 
  distinct(pub.id) -> authors_central_pubids

#str(authors_central_pubids)
#record_df_data.authors.ids$data.lens_id

#get details of publications of central authors
record_df_data.authors.ids %>% 
  filter(data.lens_id %in% authors_central_pubids$pub.id) -> authors_central_pubs
#str(authors_central_pubs)
#length(unique(authors_central_pubs$Author)) #these are all authors, many are not-central

#central authors with their papers details:
authors_central_pubs %>% 
  group_by(data.lens_id) %>%
  summarize(Paper_title = data.title, publication_type = data.publication_type, Year = data.year_published , Authors = paste(Author, collapse = "; "), Author_id = paste(value, collapse = "; ")) %>% 
  distinct_all() -> authors_central_pubs_details

#authors_central_pubs_details$data.lens_id #central authors with their papers ids
length(unique(authors_central_pubs_details$data.lens_id)) # publications across all central authors

#prepare affiliations data of all authors (note the Authir field here was not cleaned, so might be some minor mismatches)
record_df_data.authors.aff <- read.csv(here("data", "record_df_data.authors.aff_cleaned.csv"))
record_df_data.authors.aff$Author <- paste(record_df_data.authors.aff$last_name, record_df_data.authors.aff$initials, sep = ", ")

#get affiliations of central authors
record_df_data.authors.aff %>% 
  filter(data.lens_id  %in% authors_central_pubs_details$data.lens_id) %>%
  filter(Author %in% names(authors_central)) -> authors_central_aff

#str(authors_central_aff) #191 rows 
unique(authors_central_aff$Author) # unique authors captured

# #count number of papers (data.title) per Author
# authors_central_aff %>% 
#   group_by(Author) %>%
#   count()
#   
# #collapse country codes
# # authors_central_aff %>% 
# #   group_by(Author) %>%
# #   summarize(country_code = paste(country_code, collapse = "; ")) 
# #only use first country code:
# authors_central_aff %>% 
#   group_by(Author) %>%
#   arrange((data.year_published)) %>%
#   summarize(country_code = first(country_code))  #only picking first one, mostly GB

#retain more columns
authors_central_aff %>% 
  group_by(Author) %>%
  arrange((data.year_published)) %>%
  summarize(country_code = first(country_code), affiliation = first(name), N_publications = n()) -> authors_central_table  #only picking first country code and adding counts of publications

authors_central_table$affiliation <- gsub(",.*", "", authors_central_table$affiliation) #truncate affiliations at first comma

#length(authors_central) #639
#dim(authors_central_table) #582
authors_central <- authors_central[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_central) == authors_central_table$Author #check if order of names is matching

#add and arrange in a data frame:
authors_central_table$Centrality <- unname(authors_central) #add a column with degrees centrality
authors_central_table$component_orig <- as.numeric(c$membership[names(authors_central)])

#check cluster numbers - for recoding to 1 2 3 4 - used below
# as.numeric(c$membership[unique(authors_central_aff$Author)]) #pick 2 5 20 51 - see below:
# which(c$csize == 308) #2
# which(c$csize == 164) #5
# which(c$csize == 98) #20
# which(c$csize == 57) #51
authors_central_table$component_nr <- case_when(authors_central_table$component_orig == 2 ~ 1,
                                         authors_central_table$component_orig == 5 ~ 2,
                                         authors_central_table$component_orig == 20 ~ 3,
                                         authors_central_table$component_orig == 51 ~ 4
                                         ) #we only assign numbers 1,2,3,4 to members of the four biggest clusters, rest is NA

#rearrange columns and sort by cluster and centrality
authors_central_table %>% 
  select(component_nr, Centrality, country_code, Author, affiliation, N_publications) %>% 
  arrange(component_nr, Centrality) %>% 
  arrange(desc(Centrality)) %>% 
  group_by(component_nr) %>%
  slice(1:10) %>%  #pick top 10 from each component
  filter(component_nr != "NA") ->  #remove "NA" component
  authors_central_table 
  #knitr::kable() %>%
  #View()
```

#AUTHOR BETWEENNES
```{r most betweeness central authors, eval = TRUE}
g1_bet <- betweenness(g1)
hist(g1_bet) #highly skewed
authors_bet <- g1_bet[g1_bet > 1] #326 with betweenes score >1: length(names(authors_bet))
authors_bet <- authors_bet[authors_central_table$Author] #only keep ones that match names in authors_central_table
#names(authors_bet) == authors_central_table$Author #check if order of names is matching
authors_central_table$Betweenness <- round(unname(authors_bet), 1) #add a column with degrees centrality

write.csv(authors_central_table, file = here("plots", "authors_central_table.csv"))

```


